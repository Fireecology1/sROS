---
title: "Simple spread models for understory surface fires"
author: "D.D.B. Perrakis and S.W. Taylor"
output:
  word_document: 
    fig_width: 6.3
    fig_height: 6.3
  pdf_document: default
bibliography: 'C:/Dan/Zotero/My library.bib'
csl: "multidisciplinary-digital-publishing-institute.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,root.dir = 'c:/Dan/_Remote_projects/ccp-sROS')

#setwd("c:/Dan/_Remote_projects/ccp-sROS/files")

#.libPaths("C:/Dan/RPackages")

library(tidyverse)
library(broom)

#Get data frame, ready to query 
#Import data frame
fd <- read.csv('./files/fire_data_2025.csv')  # with corrected SFC from McRae, Sharp p#16 to sharp.th, PNFI R5 MC.SA, Dewdrop SFC corrected Dec 2025

#FWI and moisture functions 
load(file='./files/wbmc5.rda')
load(file='./files/mcF.rda')
load(file='./files/ISI.rda')
load(file='./files/gr-cf.rda')

#set variables for modelling
fd4 <- mutate(fd, 
              CFI=CFI1, #lower CFI only for multi-story stands
              FSG=FSG1)  #same for FSG

#Deciduous data
d1.fires <- read.csv('./files/fire_data_d1_apr2024.csv')

#Add FBP database missing VW fires: 2 C4, 2 C5
#Wildfires: GL-A (C3), Gwatkin Lk Aspen (D1), Carp Lk PNFI (C5)
#PNFI new experimental fires were similar to C4 and C5
s.miss0 <- data.frame(num=122:125, 
                      fire=c('PNFI #1 13 yr ONT',
                             'PNFI #2 12 yr ONT',
                             'PNFI RW #1-41-2', 
                             'Carp Lk PNFI WF QC'),
                     CFI1=0, Fire.type='S', 
                     ROS=c(7.6, 4.3, 3, 7.5),
                     SFC=c(NA, 0.59, NA, NA), #test - don't use estimated SFC
                     #SFC=c(1.6, 0.59, 0.3, 0.9), #only 0.59 was measured
      #Estimated SFC for 3/4 obs: C4 est: 1.64 (BUI 57); C5 est: 0.28 (BUI 25), 0.85 (BUI 45)
                     CFC=c(0, 1.0, 0, 0), 
                     Date=c('1977-05-19', '1976-08-04', 
                            '1976-05-10', '1963-07-03') %>% ymd(),
      ws=c(19, 10, 18, 25),
      FFMC=c(91.7, 89.9, 90.4, 90.7), 
      MC.FFMC=mcF(c(91.7, 89.9, 90.4, 90.7)),
      ISI=c(14.2, 7, 11.2, 16.7), 
      DMC=c(57, 26, 20, 45), 
      DC=c(107, 276, 86, 81), 
      BUI=c(57, 42, 25, 45), 
      MC.SA_season=c(1, 2, 1, 2), 
      MC.SA_dens=2, 
      MC.SA_stand=4, 
      FT='Con', #all 4 considered pine stands (conifer type)
      ExpProject=c('PNFI (JP)', 'PNFI (JP)', 'PFNI (WRP)', 'PNFI (WRP)')) 

#with ISI.mcsa values for the first two C4 PNFI fires
s.miss <- mutate(rowwise(s.miss0), 
                 MC.SA=wbmc5(FFMC, DMC, MC.SA_stand, 
                             MC.SA_dens, MC.SA_season)) %>%
                 as.data.frame() 

#Combine conifer data with D1, missing PNFI fires
fd.all <- bind_rows(fd4 %>% select(
  num:RH, Grass.Cure, Plot.Wd) %>%
    mutate(Date=ymd(Date)), 
  d1.fires %>% select(num:RH, Grass.Cure, Plot.Wd) %>%
    mutate(Date=ymd(Date)),
  s.miss) 

```

## Abstract

Surface fire behaviour is frequently observed beneath the canopy of Canadian forests under moderate wind speed and moisture deficit conditions. Surface rate of spread (sROS) models can provide guidance for suppression crews and can be incorporated into fire management tools such as fire growth modelling systems. We used a database of primarily experimental surface fires in conifer and deciduous stands to fit simple empirical sROS models that can be readily integrated within operational decision support tools. A variety of statistical forms were tested based on Canadian Fire Weather Index (FWI) System variables such as the Fine Fuel Moisture Code (*FFMC*) and Initial Spread Index (*ISI*). Additional variables tested included the  stand-adjusted litter moisture content (*mc~sa~*), a stand-adjusted ISI version (*ISI~sa~*), as well as estimated surface fuel consumption and fuel type classes. Models were evaluated using measures such as mean absolute error and Ephron's pseudo-R-squared (ER2). The simplest model finds surface ROS equal to 1.5 % of *WS~10~*, about 5-6 times slower than crown fire spread. The best performing sROS models predict nonlinear sigmoidal responses to the ISI variables, or to *WS~10~* and estimated litter moisture content. Models suitable for use in boreal conifer stands or in a range of forest types based on the aggregated data are presented, with estimated accuracy of +/- 2–4 m min^-1^ within the range of training data. While imprecise, these models should be satisfactory for many fire forecasting applications, including designing hazard reduction treatments.

### [Process - get SF data]

```{r label=site.indexes, echo=FALSE, message=FALSE}

#Index numbers for different sites
porters <- filter(fd4, str_detect(fire, "PORTER")) %>% pull(num)
sc <- filter(fd4, str_detect(fire, "PNFI SC")) %>% pull(num) #south corner fire is low dens.
pg.low <- filter(fd4, str_detect(fire, "PRINCE")) %>%
  filter(str_detect(fire, "# 4")) %>% pull(num)   #select shorter stands at PG site only
pg.high <- filter(fd4, str_detect(fire, "PRINCE")) %>% 
  filter(str_detect(fire, "# 1")) %>% pull(num)
kenshoe <- filter(fd4, str_detect(fire, "KENSHOE")) %>% pull(num)
sharp <- filter(fd4, str_detect(ExpProject, "Sharpsand IM")) %>% pull(num)  #original Sharpsand Immature stands only
sharp.th <- filter(fd4, str_detect(ExpProject, "Sharpsand TH")) %>% pull(num)
sharp.sm <- filter(fd4, str_detect(ExpProject, "Sharpsand SM")) %>% pull(num)
rp <- filter(fd4, str_detect(fire, "PNFI RP")) %>% pull(num)
darwin <- filter(fd4, str_detect(fire, "DARWIN")) %>% pull(num)  #1, 2, 6, 7 are  low density plots
darwin.low <- c(66, 67, 90, 91)
bigfish <- filter(fd4, str_detect(fire, "BIG FISH")) %>% pull(num)
icfme <- 77:87 #order is A, 1, 2, 3, 4, 5, 6, 7, 8a, 8b, 9; fixed in icfme process
icfme.hd <- c(77:79, 82:87)  #all but p3, p4
#archer <- 109:117
pelican <- 109:110  #Changed for Mar2023; was 123-124
#fpft <- c(119:122, 125:126)
dewdrop <- filter(fd4, str_detect(ExpProject, 'Dewdrop')) %>% pull(num)

#function to calculate isi.m
isi.mcsa <- function(mcsa, ws) {
  m=mcsa
  f_w= exp(0.05039*ws)
  f_f= (91.9*exp(-0.1386*m))*(1+(m^5.31)/(4.93*10^7))
  return(0.208*f_w*f_f)
}

#surface fires - extract all CFI1==0, calculate isi.m
s.fires <- mutate(rowwise(fd.all), 
                  isi.m=isi.mcsa(mc=MC.SA, ws=ws)) %>% #get ISI using MC.SA
  filter(CFI1==0) %>% 
  select(-CFI2) %>%
  mutate(FT=as.factor(case_when(
           str_detect(ExpProject, 'D1') ~ 'Decid',
           str_detect(ExpProject, 'Dewdrop') ~ 'PPDF',
           TRUE ~ 'Con'))
         ) %>%
  ungroup() %>% as.data.frame()
  
s.fires2 <- s.fires   #bind_rows(s.fires, s.miss)
```

### [Fit main SF models and PPDF]

```{r label=sROS, echo=FALSE, message=FALSE, warning=FALSE}
#ROS models 

#original ccp (2019) sf formula
sros.st <- function(isi) {
  0.6308 + 0.056*isi + 0.0086*isi^2
}

#Original unaltered conifer SF only - excludes D1, PPDF fires
s.fires.con <- filter(s.fires2, FT=='Con') 

#conifer-only isi.mcsa^2 ROS model
m4.con.lm.mod <- lm(data=s.fires.con, formula=ROS~I(isi.m^2)-1)

#conifer-only ISI^2 model
m3.con.ISI.mod <- lm(data=s.fires.con, formula=ROS~I(ISI^2)-1)
#keeper 
#use for testing fuel type significance

fun.m3 <- function(isi) {
  predict(m3.con.ISI.mod, newdata=list(ISI=isi))
}

#prediction function for simple lm using isi.m
fun.m4 <- function(isim) {
  predict(m4.con.lm.mod, newdata=list(isi.m=isim))
}

#Noted - fires with some torching seem to be anomalous
#Exceptions: fires with torching, CFC >1
except <- filter(s.fires, CFC > 0.2 | num==48) %>%
  mutate(FT='Torch')  #using this in fuel type variable for graphs

wildfires <- filter(s.fires2, num %in% c(68, 69, 76,
                                        125, 232)) %>%
  mutate(FT='WF')

#filter out fires with CFC; somewhat anomalous
#first convert all NA CFC values to 0
s.fires3 <- s.fires2 %>% 
  mutate(
    CFC=ifelse(num==48, 0.2, CFC),   #assume R3 torching based on VW68
    CFC=ifelse(is.na(CFC), 0, CFC)) %>%
            filter(CFC <= 0.2)

#Curing and C7 fires - estimate ROS under 'fully cured' condition
ppdf <- filter(s.fires3, num %in% dewdrop & !is.na(Grass.Cure))

c7.fullcuring <- 95  #fully cured is this % C
fc.cf <- gr.cf(c7.fullcuring)

#grass curing function
#0.5 actual ROS plus 0.5 of 'full curing' ROS if it was all grass

s.fires.mod0 <- s.fires3 

#SFC:
#mean(0.67, 0.47, 0.83)
#set SFC p8 to mean above
#fire 8 gets mean SFC from fires close to same time of yr, similar BUI
# s.fires.mod0$SFC[which(str_detect(s.fires.mod0$fire, 'JOHNSON EXP FIRE 8'))] <- sum(0.67, 0.47, 0.83)/3

#or, dont' make up SFC
s.fires.mod0$SFC[which(str_detect(s.fires.mod0$fire, 'JOHNSON EXP FIRE 8'))] <- NA

#Fire 9, Sept. 17 - estimate curing
s.fires.mod0$Grass.Cure[
   which(str_detect(s.fires.mod0$fire, 'JOHNSON EXP FIRE 9'))] <- 
   80 #tested a few values, 80-90

#curing for PPDF Fire 8: mean of all other fires: works out to 64
p8curing <- s.fires3 %>% filter(num %in% dewdrop) %>% select(isi.m, ROS, Grass.Cure) %>% filter(!is.na(Grass.Cure)) %>% 
  summarize(mean(Grass.Cure)) %>% as.integer()

s.fires.mod0$Grass.Cure[which(str_detect(s.fires.mod0$fire, 'JOHNSON EXP FIRE 8'))] <- p8curing 

s.fires.mod <- s.fires.mod0 %>%
  mutate(CF=gr.cf(curing=Grass.Cure),  #calculate curing factor
         ROS=ifelse(is.na(Grass.Cure), ROS,  #obs with no %C are unchanged
            ROS/2+ROS*fc.cf*(1/CF)/2))   
#ROS is half from original, half increased using inverse of curing factor

#So far these models involve - 
# - Cutting out data with CFC > 1
# - 'Detrending' PIPO fires to simulate high grass curing, half
# - including substantial percentage of D1 fires

#linear model using ISI^2
m6.sros.ISI2.mod <- lm(ROS ~ I(ISI^2)-1, data=s.fires.mod)
#r^2=0.7217 with s.fires3
#r^2=0.692 with s.fires.mod

#wind speed squared only
m5.sros.ws2.mod <- lm(ROS ~ I(ws^2)-1, data=s.fires.mod)

#lm using isi.m^2
m8.sros.isim2.mod <- lm(ROS ~ I(isi.m^2)-1, data=s.fires.mod)
#r^2=0.708 with s.fires2
#r^2=0.7605 with s.fires.mod

fun.m8 <- function(isim) {
  predict(m8.sros.isim2.mod, newdata=data.frame(isi.m=isim))
}

#lm using isi.m AND SFC - best simple model overall
m9.sros.isim2SFC.mod <- lm(ROS ~ I(isi.m^2) + sqrt(SFC)-1, 
                        data=s.fires.mod)
#r^2=0.75 with s.fires2
#r^2=0.8025 with s.fires.mod
#r^2=0.617 with s.fires.con


#similar model with ISI (sros.ISI2SFC.mod) is also good, but not as good
m7.sros.ISI2SFC.mod <- lm(ROS ~ I(ISI^2) + sqrt(SFC) - 1, 
                       data=s.fires.mod)
#r^2=0.7501

#prediction functions
# sf.lin.fun <- function(ws) {
#   predict(sros.lin.mod, newdata=list(ws=ws))
# }

#nls model and prediction function: ax^b format
m12.sf.axb.isi.mod <- nls(data=s.fires.mod, formula= 
               ROS ~ a * ISI^b, start=list(a=1, b=2))

sf.axbisi.fun <- function(isi) {
  predict(m12.sf.axb.isi.mod, newdata=list(ISI=isi))
}


#fake data for lines - isim2SFC / IsaSFC model; fros1 is at SFC=1.34, fros2 is at SFC=2
#also ISI2SFC model and 
f.sfires0 <- data.frame(fisim=seq(0:30), fsfc1=1.34, fsfc2=2)
f.sfires <-mutate(rowwise(f.sfires0),
              fros1=predict(m9.sros.isim2SFC.mod, 
              newdata=list(isi.m=fisim, SFC=fsfc1)),
              fros2=predict(m9.sros.isim2SFC.mod, 
              newdata=list(isi.m=fisim, SFC=fsfc2)))

#FBP/Van Wagner models:
c6s <- function(isi) {
  ros=30 * (1-exp(-0.08*isi))^3
  return(ros)
}

#vw 1993 surface model for c4 immature pine stands; changed to c4s
#sf.vw93i
c4s <- function(isi) {
 20*(1-exp(-0.2*isi))^5 
}

#vw 1993 surface model for c3 mature pine stands
#sf.vw93m
c3s <- function(isi) {
 15*(1-exp(-0.05*isi))^2 
}

#D1
#sf.d1 
d1 <- function(isi) {
  30*(1-exp(-0.0232*isi))^1.6 
}

#c3 if needed
c3 <- function(isi) {
  110*(1-exp(-0.0444*isi))^3
}


#fit Chapman-Richards function to surface fire data
a.value <- 25 

sf.crisim.mod <- nls(data=s.fires.mod, formula= 
               ROS ~ a.value * (1-exp(-b*isi.m))^c, 
               start=list(b=0.08, c=3))


#just need to make a function from the model
sf.crisim.fun <- function(isim) {
  predict(sf.crisim.mod, newdata=list(isi.m=isim))
}
  
#Using ISI
sf.crisi.mod <-nls(data=s.fires.mod, formula= 
               ROS ~ a.value * (1-exp(-b*ISI))^c, 
               start=list(b=0.1, c=3))

#CR nls function using ISI
sf.crisi.fun <- function(isi) {
  predict(sf.crisi.mod, newdata=list(ISI=isi)) %>% unname()
}

#Conifer obs only!
###################
#recall con.lm.mod and con.ISI.mod
s.con <- s.fires.mod %>% filter(FT=='Con') #same as s.fires.con

sf.crisiCon.mod <-nls(data=s.con, 
                formula= 
               ROS ~ a.value * (1-exp(-b*ISI))^c, 
               start=list(b=0.1, c=3))

sf.crisiCon.fun <- function(isi) {
  predict(sf.crisiCon.mod, newdata=list(ISI=isi)) %>% unname()
}

#isi.m
sf.crisimCon.mod <-nls(data=s.con, 
                formula= 
               ROS ~ a.value * (1-exp(-b*isi.m))^c, 
               start=list(b=0.1, c=3))

sf.crisimCon.fun <- function(isim) {
  predict(sf.crisimCon.mod, newdata=list(isi.m=isim)) %>% unname()
}

#test for pine/spruce/other difference
s.con2 <- mutate(s.con, 
                 FT2=str_extract(ExpProject, "\\([^()]*\\)"), #all inside ()
                 FTsp=str_detect(FT2, 'S') %>% as.factor(),
                 FT3=case_when(
                   str_detect(FT2, '/') ~ 's',  #mix of pine /spruce
                   str_detect(FT2, 'S') ~ 's',  #spruce only
                   str_detect(FT2, '(JP)') ~ 'jp',         #jack pine only
                   TRUE ~ 'op') %>% as.factor())  #other pines
                 
#test for sig. of Fuel type factors
con.ft2 <- lm(ROS ~ I(ISI^2) + FTsp -1, data=s.con2) #NS
con.ft3 <- lm(ROS ~ I(ISI^2) + FT3 -1, data=s.con2) 
#FT3 is actually significant, with 'other pine sp' sig. lower ROS than jp
#testing contrast:
#emmeans_output <- emmeans(con.ft3, ~FT3)
#multcomp::cld(emmeans_output, alpha=0.05, Letters=letters)
#shows op <> jp (op=s and s=jp though)

#summary(update(sros.ISI2SFC.mod, ~ I(ISI^2) + sqrt(SFC) + FT3 - 1, data=s.con2))
#SFC models are NS when applied to conifer-only dataset; Fuel type then also 
#becomes NS (P > 0.05)


#Add function for ISI2SFC and ISI.mSFC models
sf.isi2sfc.fun <- function(isi, sfc) {
  predict(m7.sros.ISI2SFC.mod, newdata=list(ISI=isi, SFC=sfc)) %>% 
    unname()
}

sf.isim2sfc.fun <- function(isim, sfc) {
  predict(m9.sros.isim2SFC.mod, newdata=list(isi.m=isim, 
                                          SFC=sfc)) %>%
    unname()
}

#SFC=0.75
sf.isim2sfc075.fun <- function(isim) {
  sfc_vals=rep(0.75, length(isim))  #required for stat_function
  predict(m9.sros.isim2SFC.mod, 
          newdata=list(isi.m=isim, SFC=sfc_vals))
}

#SFC=1.5
sf.isim2sfc15.fun <- function(isim) {
  sfc_vals=rep(1.5, length(isim))  #required for stat_function
  predict(m9.sros.isim2SFC.mod, 
          newdata=list(isi.m=isim, SFC=sfc_vals))
}

#SFC=3
sf.isim2sfc3.fun <- function(isim) {
  sfc_vals=rep(3.0, length(isim))  #required for stat_function
  predict(m9.sros.isim2SFC.mod, 
          newdata=list(isi.m=isim, SFC=sfc_vals))
}

#SFC=1.5 with ISI function
sf.isi2sfc15.fun <- function(isi) {
  sfc_vals=rep(1.5, length(isi))  #required for stat_function
  predict(m7.sros.ISI2SFC.mod, 
          newdata=list(ISI=isi, SFC=sfc_vals))
}

#Initial FT model 15 below


#Fernandes sf (Fernandes et al. 2009) model for 
#maritime pine stands based on ws, litter mc, fuel depth
#Eq 6, for 0 slope case
#not clear what height for ws measurements...
sf.fernandes <- function(ws, mc, fd) {
  ROS=0.773*ws^0.707*exp(-0.039*mc)*fd^0.188
  return(ROS)
}

#trying Fernandes' power law form:
#see [slope asymptote] section for Power law model fits

#Add ISI-FT and isim-FT models
# sf.nope <- nls(data=s.fires.mod %>% filter(FT=='Con'), 
#                ROS ~ 0.5*ws^a*exp(-b*MC.SA)^c, 
#                start=list(a=0.7, b=0.1, c=3))  #gives error

#All this stuff to try to do a Tukey test but it's almost all NS anyway
#only sig. difference is between PPDF and other 2 FTs (but screwy because of 
#the 'normalizing' to 95% curing)

#Fix database to calc mcF and other missing features
s.fires.mod2 <- mutate(s.fires.mod, FT=as.factor(FT),
                       MC.FFMC=mcF(FFMC))

#make conifer the 'base' factor level for contrasts
s.fires.mod2$FT <- relevel(s.fires.mod2$FT, ref='Con')

sf.ftSFC <- lm(ROS ~ I(isi.m^2) + SFC + FT -1, 
              data=s.fires.mod2) #SFC NS

sf.ftim2 <- lm(ROS ~ I(isi.m^2) + FT-1, 
              data=s.fires.mod2) #FT Not sig. Was called m16 briefly

sf.ftim3 <- lm(ROS ~ I(isi.m^2) * FT-1, 
              data=s.fires.mod2) #very sig., but interaction is messy


m15x.sf.ftisi <- lm(ROS ~ ISI * FT -1, 
              data=s.fires.mod2) #linear w/ interaction; use for ISI < 15
#careful for ISI higher than that (PPDF is low)

sf.ftisi2 <- lm(ROS ~ I(ISI^2) + FT -1, 
              data=s.fires.mod2) #squared, no interaction

sf.ftisi3 <- lm(ROS ~ I(ISI^2) * FT -1, 
              data=s.fires.mod2) #ISI squared, with interaction

#Multiple comparisons - Tukey test
#try 'emmeans' package
# require(emmeans)
# ##require(multcomp) #note - this screws up dplyr::select !!
# 
# emmeans_output <- emmeans(sf.ftisi, ~ FT)
# emmeans_output <- emmeans(sf.ftisi2, ~ FT)

# multcomp::cld(emmeans_output, alpha = 0.05, Letters = letters)
# or
# contrast(emmeans_output, method = "revpairwise", adjust = "tukey")

#FT differences sig. (sf.ftisi only) 


#Consider adding one:
# sf.ftisi  
ft.isi.fun <- function(isi, ft='Con', mod=1) {
  ft_vals=rep(ft, times=length(isi))
  mod_vals=rep(mod, times=length(isi))
  return(case_when(mod==1 
                   ~ predict(m15.sf.ftisi, newdata=list( #this one will do
                     ISI=isi, FT=ft_vals)),
                   mod==2 
                   ~ predict(sf.ftisi2, newdata=list( 
                     ISI=isi, FT=ft_vals)),
                   mod==3
                   ~ predict(sf.ftisi3, newdata=list(
                     ISI=isi, FT=ft_vals))))
  #FT levels: Con, PPDF, Decid
  #mod1: linear; mod2: squared, not inter; mod3: squared, with inter
}


#new model - Fuel type ISI model with oblique asymptote 
#s.fires.mod2 <- s.fires.mod

s.fires.mod2$FT_P <- as.numeric(s.fires.mod$FT =='PPDF')
s.fires.mod2$FT_D <- as.numeric(s.fires.mod$FT =='Decid')

asy.slope1=0.15
asy.yInt1=10
  
m18.agAsy.FT <-nls(data=s.fires.mod2, formula= #substitute for sf.crisi.mod
    ROS ~ (asy.slope1 * ISI + asy.yInt1) * (1-exp(-b*ISI))^c +
     aP*FT_P + aD*FT_D, start=list(b=0.1, c=3, aP=0, aD=0))
##aP and aD both significant?! 
#not used - see 'slope asymptote models'

fun.m18 <- function(isi, ftp=0, ftd=0) {
  predict(m18.agAsy.FT, newdata=list(ISI=isi, FT_D=ftd, FT_P=ftp))
}
#Use this for a fuel type function (m18)
#Extended SFC/FT table


# ft.isi2.fun <- function(isi, ft='Con') {
#   ft_vals=rep(ft, times=length(isi))
#   predict(sf.ftisi2, newdata=list(ISI=isi, FT=ft_vals))
#   #FT levels: Con, PPDF, Decid
# }

#save(sf.ftisi, file='C:/Dan/_Remote_projects/ccp-sROS/files/sf_ftisi.rda')
#save(ft.isi.fun, file='C:/Dan/_Remote_projects/ccp-sROS/files/ftisi_fun.rda')
#write.csv(s.fires.mod, file='C:/Dan/_Remote_projects/ccp-sROS/files/sfires_mod.csv')
#write.csv(s.fires3, file='C:/Dan/_Remote_projects/ccp-sROS/files/sfires3.csv')


```

### [Complex modelling attempts]

```{r fancy modeling attempts, echo=FALSE}

##Then try rpart models
rp.mods <-rpart::rpart(ROS ~ ., data=s.fires.mod %>% 
                  select(ROS, ws, FFMC, ISI, MC.SA, isi.m, SFC, FT),
                  method='anova')
#Hmmm. Tree models. Too complicated to make sense of

#leaps
#first make dataset with squared terms
s.fires.squared <- s.fires.mod %>%
  mutate(ws2=ws^2, 
         ISI2=ISI^2,
         isi.m2=isi.m^2,
         SFC2=SFC^2,
         SFC.sqrt=sqrt(SFC),
#         FT=as.factor(FT),
         MC.SA_dens=as.factor(MC.SA_dens)
         ) %>%
  select(ROS, ws, ws2, FFMC, ISI, ISI2, MC.SA, isi.m, isi.m2, 
         SFC, SFC.sqrt, FT, MC.SA_dens, DMC, MC.FFMC) #SFC2

lp.mods <- leaps::regsubsets(ROS ~ ., 
                             data=s.fires.squared, #force.out='DMC', 
                             nbest=1, nvmax=4)

lp.mods2 <- leaps::regsubsets(ROS ~ ., 
                             data=s.fires.squared,
                             method='exhaustive',
                             nbest=3, nvmax=4) #intercept=FALSE

lp.mods3 <- leaps::regsubsets(ROS ~ ., 
                             data=s.fires.squared, 
                             nbest=4, nvmax=5, 
                             method = 'exhaustive') #,
                            # intercept=FALSE)


#summary(lp.mods)

best2 <- lm(ROS ~ isi.m2+MC.SA_dens -1, data=s.fires.squared)
#density factor is illogical
linisimmod <- lm(ROS ~ isi.m-1, data=s.fires.squared) #linear isi.m
linwsfmmod <- lm(ROS ~ MC.SA + ws -1, data=s.fires.squared) #linear ws, mcSA

isimmod <- lm(ROS~ isi.m2 -1, data=s.fires.squared) #isi.m squared
wsfmmod <- lm(ROS~ MC.SA + ws2 -1, data=s.fires.squared) #ws2 + mcSA

linisi <- lm(ROS ~ ISI-1, data=s.fires.squared) #linear ISI 
linwsffmmod <- lm(ROS ~ ws + MC.FFMC -1, data=s.fires.squared) #lin ws, ffmc

isimod <- lm(ROS ~ ISI2-1, data=s.fires.squared) #ISI squared
wsffmmod <- lm(ROS ~ ws2 + MC.FFMC -1, data=s.fires.squared)  #ws squared and FFMC

wsmod <- lm(ROS ~ ws2-1, data=s.fires.squared)
linws <- lm(ROS ~ ws-1, data=s.fires.squared)

#based on RMSE, ER2, MAE, MAPE:
#ISI_sa2 better than ISI2 model
#ISI_sa better than ISI model for full dataset

#rcompanion::accuracy(isimmodel)

#linear ISI_sa is better than ws + mcSA
#ISI_sa2 is better than ws2 + mcSA

#ISI2 is not clearly better or worse than ws2 + mcFFMC (ER2 and MAPE better, RMSE and MAE worse)
#linear ISI is not clearly better or worse than ws + mcFFMC (ER2 better, RMSE, MAE and MAPE worse)

#DMC factor was illogical, so excluded
#'exhaustive' search for all var combinations revealed models dominated by isi.m2; alone (1 var), with FFMC (2), with FFMC and ISI(3), or with FFMC, ISI, ws2 (4). Gains compared with isi.m2 model alone are very slight, suggesting overfitting. 


#con dataset with squared 
s.fires.cosquared <- s.fires.con %>%
  mutate(ws2=ws^2, 
         ISI2=ISI^2,
         isi.m2=isi.m^2,
         SFC2=SFC^2,
         SFC.sqrt=sqrt(SFC),
         ) %>%
  select(ROS, ws, ws2, FFMC, ISI, ISI2, MC.SA, isi.m, isi.m2, 
         SFC, SFC2, SFC.sqrt, MC.SA_dens, DMC)

lp.mods.con <- leaps::regsubsets(ROS ~ ., 
                        data=s.fires.cosquared, force.out='DMC',
                             nbest=3, nvmax=4, intercept=FALSE)  #DMC was bogus
#DMC estimate again negative, so excluded
#test MC.SA_season factor?

best2c <- lm(ROS ~ ISI2 + ISI -1, data=s.fires.cosquared) #no good

```

### [graphs and functions]

```{r label=graphs, echo=FALSE}
#for graphing purposes, assign median SFC to all with no SFC
est.sfc <- s.fires.mod %>% filter(is.na(SFC)==TRUE) %>%
  mutate(SFC=1) #overall mean SFC is 0.991

s.graph <- bind_rows(s.fires.mod %>% filter(!is.na(SFC)), 
    est.sfc) #data frame of all obs, including is.na(SFC)

ppdf.orig <- s.fires3 %>% filter(!is.na(SFC) & FT=='PPDF') %>%
              full_join(est.sfc %>% filter(FT=='PPDF') %>% 
                          mutate(ROS=2.1)) #return to orig. ROS
  
fig4 <- ggplot(s.fires.mod, 
       aes(x=isi.m, y=ROS)) +  
  scale_fill_manual(values=c(
    'red2',
    'blue4',
    'green3')) +
  geom_point(aes(fill=FT, size=SFC, colour=FT), shape=21, 
             alpha=0.5) + #main fires, adj. PPDF
  geom_point(data=est.sfc, aes(fill=FT, size=SFC), shape=21, 
             colour='black', alpha=0.5) + #show fires with est. SFC (blk rim)
  geom_point(data=ppdf.orig, 
             aes(size=SFC), shape=21, color='darkgray', 
             fill='darkgray', alpha=0.5) + #PPDF original ROS
  geom_point(data=wildfires, colour='black', fill='black', size=1, 
             shape=21) + #wildfires with sm black dots in middle
#  geom_line(data=f.sfires, aes(x=fisim, y=fros1), colour='gray')+
  theme_classic()
#  stat_function(fun=sf.con.fun, colour='gray') +
  #geom_text(x=28, y=sf.isim2sfc075.fun(28)+3, 
  #          label='IsaSFC') +
  

#fig4

#Graph with vw functions, ISI
fig5 <- ggplot(s.graph, 
       aes(x=ISI, y=ROS)) + 
    scale_colour_manual(values=c(
    'red2',
    'blue4',
    'green3')) +
  geom_point(aes(colour=FT, size=SFC), alpha=0.5) +    
  geom_point(data=s.fires3 %>% 
               filter(FT=='PPDF'), aes(size=SFC), shape=21,                        fill='darkgray', alpha=0.5) + #PPDF original
  geom_point(data=wildfires, colour='black', fill='black', size=1, 
             shape=21) + #wildfires
  #geom_line(data=f.sfires, aes(x=fisim, y=fros1), colour='gray') + #IsaSFC model
#  stat_function(fun=sf.axbisi.fun, color='grey') +
  stat_function(fun=c4s, color='gray', linetype='dashed') +
  stat_function(fun=c3s, color='gray', linetype='dashed') +
  stat_function(fun=c6s, color='gray', linetype='dashed') +
   # geom_text(x=21, y=c6s(21)-1, label='C6s') +
  theme_classic()

#fig5

```

## 1. Introduction

The rate of spread (ROS), or rate of forward advance, of a wildfire is probably its most important behaviour characteristic for fire managers [@vanwagner1965; @Sullivan.Gould2020]. Fire spread in Canadian forests is often a story about conifer crown fires, featuring high spread rate and intensity, a rain of lofted embers and few suppression options [@alexander2016]. And yet in the chronology of fire events, most days between ignition and extinction feature only ground or surface fire behaviour [@wang2014]. Surface fires can often be safely and routinely actioned by suppression crews and equipment [@wheatley2022], and managers need to be able to estimate the speed and intensity of fires even when crown fire activity is unlikely.

### Surface fire spread in the Canadian Fire Behavior Prediction System

Surface fire spread models have been incorporated into previous Canadian fire behaviour modelling studies, though they have rarely been the main focus. The present Fire Behavior Prediction (FBP) System features fuel-type specific models encompassing the full range of surface through crown fire behaviour for a small number of distinct conifer fuel complexes [@forestrycanadafiredangergroup1992; @tymstra2010]. Thus, the majority of conifer and mixedwood ROS models do not discriminate between surface and crown fire behaviour but rather assume a gradual transition between fire types – a deliberate decision discussed during the system's development [@vanwagner1989a]. However, a number of more flexible conifer modelling schemes have emerged since then that specify the type of fire predicted under given weather and moisture inputs. These include CFIS (Crown Fire Initiation and Spread), Conifer Pyrometrics, and the promise of dynamic fuels and specific crown fire transition in the forthcoming version of the Canadian FBP System, FBP2025 [@Alexander.etal2006a; @perrakis2020; @cfsfiredangergroup2021]. In the US, the Rothermel surface ROS model [@rothermel1972] has been used operationally for over 40 years [@andrews2018], though its required inputs and US-focus have largely kept it out of operational use in Canada. All of these systems attempt to address the question via empirical or quasi-empirical means [@sullivan2009] of what fire behaviour to expect (ROS, fire intensity, etc.) in the forest understory when crown fire involvement is not expected.

We first note that a few empirical surface fire model options exist in the current FBP System for fuel types lacking a flammable overstory: leafless deciduous forests (D-1), open vegetation (i.e. grassland; O-1), and scattered logging slash (S-1 through S-3) [@forestrycanadafiredangergroup1992; @wotton2009]. As with the full integrated (surface and crown fire) conifer fuel type models, initial surface ROS (sROS or RSI) equations are based on the sigmoidal Chapman-Richards function [@vanwagner1989a]. 

$$ROS=a(1-e^{-b\cdot ISI})^c$$ [Eq.1].

In this equation, the *a* parameter represents a horizontal asymptote ('levelling off value'); the *b* and *c* parameters are assigned or fitted from data [@forestrycanadafiredangergroup1992]; and *ISI* represents the Initial Spread Index from the Fire Weather System [@vanwagner1987]. Newer surface fire models have also been developed for grass [@wotton2009b; @kidnie2015] and proposed for Atlantic shrublands [@Pepin.Wotton2020]. A few older sROS models were previously published based on individual field experiments [e.g., @Lawson1972], but these data were eventually incorporated into the broader-scope FBP fuel type functions.

### CE Van Wagner's surface fire models

As the FBP System was being developed, CE Van Wagner (CEVW) proposed a theoretical dual equilibrium conifer crown fire model concept. This involved two notional functions for a given conifer stand: the first described the expected ROS of crown fires, *RSC*, while the second represented "all possible surface fires", *RSS* [@vanwagner1989a]. CEVW's well known crown fire initiation model could then be used to estimate the transition point between the two [@vanwagner1977a]. The *RSS* function parameters appeared in the FBPS report in the form of the C-6s model, for the surface fire portion of the 'Conifer Plantation' fuel type: *a*=30, *b*=0.080, *c*=3 [@forestrycanadafiredangergroup1992]. Two additional RSS-type models and parameters were suggested by CEVW shortly after the FBP System was published, associated with surface fire spread in immature and mature jack pine (*Pinus banksiana*) stands in Ontario [@vanwagner1993a]. The immature pine model was associated with experimental observations from what became the C-4 fuel type [@stocks1987b]; "C-4s": *a*=20, *b*=0.20, *c*=5; while a mature pine RSS model was associated with some of the experiments that were later incorporated into the C-3 model [C-3; @stocks1989]; "C-3s": *a*=15, *b*=0.05, *c*=2 [@vanwagner1993a]. No statistics or other source were provided for the origin of these models (C-3s, C-4s, C-6s); it appears they were proposed based on iteration and visual inspection alone. Figure 1 compares these RSS functions alongside with the D-1 and C-3 FBP System models.

### [Fig1]

```{r label=Fig1, message=FALSE, echo=FALSE}

fig1 <- ggplot(data=s.fires, aes(x=ISI, y=ROS)) +
  stat_function(fun=c6s, colour='darkred') +
  stat_function(fun=c4s, colour='turquoise') +
  stat_function(fun=c3s, colour='purple') +
  stat_function(fun=d1, colour='green') +
  stat_function(fun=c3, colour='gray') +
  geom_text(x=10, y=c4s(10)+3, label='C-4s') +
  geom_text(x=15, y=c6s(15)-2, label='C-6s') +
  geom_text(x=24, y=d1(24)+1, label='D-1') +
  geom_text(x=22, y=c3s(22)-1, label='C-3s') +
  geom_text(x=20, y=c3(20)+1.5, label='C-3') +
  coord_cartesian(x=c(2, 25), y=c(0, 35)) +
  theme_classic() +
  labs(y='ROS (m/min)')
  

fig1

```

*Caption: Figure 1. Comparison of surface fire rate of spread (ROS) models from the FBP System and associated research; the C-3 model (continuum of surface to crown fire ROS) is included for comparison purposes. The D-1 and C-6s models are a core part of the FBP System. C-4s and C-3s refer to surface fire models proposed by C.E. Van Wagner for immature and mature jack pine fires, respectively. ISI refers to the Initial Spread Index.*

### Objectives

The objective of this study was to use the Canadian database of experimental fires to produce simple empirically-based models for estimating the ROS of surface fires burning beneath the canopy of boreal and sub-boreal forest stands. Such models can be incorporated into dynamic fire behaviour predictions systems, where surface fire, crown fire initiation, and crown fire spread are modelled as separate but related processes [@scott2001; @perrakis2020; @cfsfiredangergroup2021]. A secondary objective was to evaluate and quantify the performance of existing models of surface fire spread used in Canada.

It has long been known that ambient wind speed is one of the most important predictors of ROS [@vanwagner1968; @catchpole1998; @rothermel1972]. However, beneath a forest canopy, predicting wind speed at the microclimate level involves detailed studies of wind interactions with forest structure, including edge effects as well as the influence of subcanopy vegetation [@moon2019; @schlegel2015]. Although this approach has been used in the US and elsewhere, it demands a fine-scale landscape wind-vegetation analysis which is seldom available in operational settings. The present models therefore rely only on the standard 10 m open wind speed (*WS~10*), as was measured in field experiments and is typically used for wildfire weather forecasts [@lawson2008]. This is appropriate for operational use, but means that model predictions are expected to be noisy when applied across the spectrum of forest structure and density due to the influence of varying edges and openings on moisture and understory winds [@chen1999; @ma2010].

## 2. Methods

### Fire database

The main source data for these analyses is a slowly growing database of field-scale experimental burns conducted at various sites across Canada since the mid-20th century, presently ranging from 1960-2020. Most of these data have previously been described and analyzed [@alexander1990; @cruz1999a; @perrakis2023], but never before for the purpose of developing operational surface fire models. Over 120 observations of fire behaviour originated from field-scale experimental burn plots (median size: 0.4 ha) in boreal and sub-boreal conifer forests. These fires were described as surface or crown fires according to published reports or unpublished field notes by original observers; crown fires were further estimated as passive or active, according to Van Wagner's [@vanwagner1977] original descriptions. In addition, 39 additional experimental surface fire observations were available in other forest types and provide additional insight for general sub-canopy fires. These include 32 fires in deciduous forests, including 6 fires from trembling aspen (*Populus tremuloides*) stands of the northeastern US [@alexander1989a]; 14 fires in aspen near Hondo, Alberta [@quintilio1991]; and aspen (9), oak (*Quercus* sp.) (2), and aspen-dominated mixedwood (1) fires near Petawawa, Ontario [@vanwagner1973]. Finally, seven experimental surface fires in Ponderosa pine (*P. ponderosa*) - Douglas-fir (*Pseudotsuga menziesii*) stands (PPDF) in British Columbia were also included, analyzed somewhat uniquely to simulate cured grass conditions, discussed in detail below. To supplement the experimental data, a small number of well-documented wildfire observations were included in the analysis, presently consisting of three surface fires observed under higher fire danger conditions than most of the experimental dataset. Out of the full database of `r nrow(fd.all)` observations, `r nrow(fd.all %>% filter(CFI1==0))` were described as surface fires in primary sources and are used in for surface ROS modelling.

### Modelling and spread indices

We anticipated that wind speed and dead fuel moisture content would be primary variables of interest, consistent with longstanding theoretical understanding of fire processes [@curry1940; @vanwagner1968; @campbell-lochrie2021] and the majority of existing empirical models [@fernandes2009; @sullivan2009]. In particular, the aforementioned unitless *ISI* that combines empirical functions representing *WS~10~* and fuel moisture influences [@vanwagner1987] was already the main independent variable used for predicting ROS in the FBP System [@forestrycanadafiredangergroup1992]. Other variables we examined for significance included moisture indices from the FWI System (the Fine Fuel Moisture Code, *FFMC*, and Duff Moisture Code, *DMC*). Since litter moisture was not measured on many fires, these indices can be used to estimate litter moisture in many forest types and have been shown to be generally reliable [@wotton2009a]. Surface fuel consumption (*SFC*) was also tested, which was measured on most fires but must be estimated or modelled separately for prediction purposes. 'Fuel type' is the term presently used to identify the dominant forest overstory species associated with a particular plot or wildfire, and was tested as a categorical variable in analyses. The lone surface fire observation in black spruce (*Picea mariana*) was grouped with five observations in mixed jack pine- black spruce stands in order to separate spruce-containing observations (S) from the fires in boreal pine-dominated stands.

In addition to the base ISI, which is calculated from the wind speed and estimated litter moisture content (*mc*) from the FFMC [@vanwagner1987], we also explored a modification using a more flexible fuel moisture model, the stand-adjusted moisture content (*mc~sa~*) model of Wotton and Beverly [@wotton2007; @perrakis2023]. The *mc~sa~* combines the effects of the FFMC and DMC indices along with categorical stand type, density, and season variables for directly predicting the moisture content of litter moisture, a considerably more flexible predictor set than the FFMC alone. The *mc~sa~* was combined with wind speed using the identical formula as originally described for the ISI, with the *mc~sa~* in place of the FFMC-based *mc*. The full *ISI~sa~* equation is provided here for completeness:

$$ ISI_{sa}=0.208\cdot (e^{0.05039\cdot WS_{10}}) \cdot (91.9 \cdot e^{-0.1386\cdot mc_{sa}}) \cdot \left[ 1+\frac{mc_{sa}^{~~~5.31}}{(4.93\cdot 10^7)}) \right]  $$ [Eq.2].

For model feature selection, we tested weather and fuel predictors: *WS~10~*, *FFMC*, *mc~sa~*, *DMC*, *ISI*, *ISI~sa~*, *SFC*, fuel type, and stand density class ('light', 'moderate', and 'dense' classes, as defined by [@wotton2007]), as well as transformed terms: *WS~10~*^2^, *ISI^2^*, *ISI~sa~^2^*, *SFC^2^*, and *sqrt(SFC)*. All variable combinations (1-5 predictors) were tested using an exhaustive variable search with the R function 'leaps::regsubsets()' [@lumley2024]. After confirming the predictive value of ISI (see Results, below), we also tested two types of non-linear responses. The first used a modification of the sigmoidal Chapman-Richards equation (eq. [1]). The horizontal asymptote, *a*, was replaced with a linear function, $y=m \cdot ISI+i$ [Eq.3], with *m* and *i* being assigned or fitted slope and y-intercept parameters, respectively. At high ISI values, ROS therefore approaches the value of *y*:

$$
ROS=(m \cdot ISI + i) \cdot (1-e^{-b \cdot ISI})^c
$$

[Eq.4].

This oblique linear asymptote is believed to be more realistic for representing subcanopy ROS under more severe (drier, windier) conditions compared with the fixed asymptote value in the original function (eq. [1]).

The second nonlinear form was adapted from the flexible power law form previously used by several authors for various forms of empirical fire models [@cheney1998; @fernandes2009; @anderson2015]. This form uses *WS~10~* and litter moisture content (*mc*) as separate predictors, and fits additional coefficients to variables such as slope and fuel depth, when sufficient observations are available [@fernandes2009]. Since none of our fires were on sloped terrain and most did not have measured forest floor depth measurements, we fitted up to three coefficients according to the equation: 
$$
ROS=a \cdot WS_{10}\ ^b \cdot exp(-mc)^c
$$
[Eq. 5#]. Here, *mc* represents the estimated litter moisture content using either the *FFMC* or *mc~SA~* estimates, and *a*, *b*, and *c* are fitted to the data. Aside from separating the *ISI* into individual wind and moisture influences, eq. 5 has the advantage of fitting the *WS~10~* exponent rather than assuming a constant (Eq. 1) or linear function (Eq. 4) asymptote under high fire danger conditions. 

Potential fitted models were compared using common evaluation metrics for linear and non-linear models: root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and Ephron's pseudo-r-squared (ER2). ER2 is a measure that is appropriate for comparing the variability represented by models when widely-divergent predictor forms are being compared, including linear, non-linear, and forced-intercept models [@Mangiafico2015]. All analyses were performed in RStudio 2024.04 (Posit Software, Boston, MA, USA) with R version 4.2.1.

### Grass curing in Ponderosa Pine fires

For the PPDF fires (see Appendix A), we sought to incorporate the effects of understory grass and herbaceous curing effects, as graminoids represent an important part of the understory fuelbed in these forests [@ducherer2009; @ducherer2013] and grass curing is known to be highly influential on fire spread in grass fuel types [@cruz2015b]. Since a predictive model incorporating the degree of curing (C) would require much more data, we estimated how fire spread in these stands under peak seasonal conditions based on certain assumptions from known grassland fire spread mechanisms. We first normalized all observations, following Cheney [@cheney1995], to a nearly fully cured grass condition (95% C) in order to represent early spring or late summer conditions associated with high fire danger. Although the grass biomass in these stands only represented a fraction (\~3 %) of the total available surface fuel [@nyberg1979], grass curing has been observed by operational practitioners to have a strong influence on ROS in Ponderosa pine stands [@beck2003]. We assumed that understory grass and forb curing in these pine-Douglas stands would be half as influential compared to curing influence in a true grassland, due to the larger portions of the litter load from needles and woody debris [@nyberg1979]. We therefore calculated new 95% C estimated ROS (*ROS'*) values for these plots as follows:

$$ ROS'=\frac {ROS_0}{2} \cdot \left[ {1 + \frac {cf(95)} {cf(C)}} \right]  $$

[Eq.5], where *ROS~0~* represents the observed rate of spread with measured curing *C* (see Appendix A), and *cf(C)* and *cf(95)* represent the calculated curing factors [@wotton2009] at measured % C values and 95% C, respectively. *ROS'* values for these seven PPDF fires were then used in model fitting.

## 4. Results

### Initial data exploration and model building

Simple inspection of surface and crown fires in our database revealed certain obvious patterns. Among `r nrow(fd.all)-nrow(d1)` fires in conifer stands, a clear, though noisy linear relationship is evident between ROS and wind speed that differs by type of observed behaviour: surface, passive crown, and active crown fires (Fig. 2).

### [Fig 2 simple ROS graph by fire type and eval for m25 and FBP mods]

```{r label=Fig2, message=FALSE, echo=FALSE, warning=FALSE}
#Call all 'midstory passive crown fires' surface fires if
#CFC is less than 0.1
fd.ros0 <- mutate(fd4, #conifer only; could do with fd.all for decid, ppdf too
                 FiT2=case_when(
                   Fire.type=='PCM' & CFC < 0.1 ~ 'S',
                   Fire.type=='PCM' & CFC >= 0.1 ~ 'PC',
                   TRUE ~ Fire.type)) %>%
  select(num, fire, ws, ROS, ISI, SFC, FiT2)
  
fd.ros1 <- bind_rows(
  fd.ros0, s.miss %>% select(num, fire, ws,
                        ROS, ISI, SFC, FiT2=Fire.type))

#remove wildfires - cancel, don't do this
 fd.ros <- fd.ros1 
#%>%
#  filter(!num %in% c(68, 69, 76, 125))

#25% rule?
m25 <- function(x) {0.25*x}
m20 <- function(x) {0.2 *x}

fig2 <-ggplot(fd.ros, aes(x=ws, y=ROS, colour=FiT2))+ #plot all surf and cr fires
  geom_point(alpha=0.7)+ #points
  xlim(0, 35)+
  stat_function(fun= m25, colour='black') + # 25% ws model
#  stat_function(fun=m20, colour='black')+ # 20% ws model
  scale_colour_manual(values=c('red', 'orange', 'green')) +
  geom_smooth(method='lm', se=FALSE, level=0.95) + #smooth ws line by fire type
  theme_bw() +
  labs(x=c(expression(WS[10]), ' (km/h)'), 
       y='ROS (m/min)', colour='Type of fire') +
  theme(legend.position=c(0.1, 0.8)) +
  theme(legend.background=element_rect(fill='white', colour='black'))


#simple linear sROS model from graph:
m1.sf.lin.ws <- lm(ROS ~ ws, data=fd.ros %>% filter(FiT2=='S'))

#m1 intercept
m1.int <- summary(m1.sf.lin.ws)$coef[1]

##########################
#test m25 vs m20
fd.m25 <- fd.ros %>% filter(FiT2=='S')
b_25 <- 0.25
b_20 <- 0.2
test25 <- lm(ROS ~ 1 + offset(ws*b_25) -1, data=fd.m25)
test20 <- lm(ROS ~ 1 + offset(ws*b_20) -1, data=fd.m25)

#compute sum of squared error
rmse25 <- broom::augment(test25) %>% 
  select(.resid) %>% 
  mutate(r2 = .resid^2) %>% summarize(rmse=sqrt(sum(r2)/nrow(fd.m25)))

rmse20 <- broom::augment(test20) %>% 
  select(.resid) %>% 
  mutate(r2 = .resid^2) %>% summarize(rmse=sqrt(sum(r2)/nrow(fd.m25)))

#check SSE for higher ws values (ws>10 or 15)
rmse25hi <- broom::augment(test25) %>% 
  mutate(ws=`offset(ws * b_25)` * 4) %>%  #get back to original ws
  filter(ws > 15) %>%
  select(.resid) %>% 
  mutate(r2 = .resid^2) %>% summarize(rmse=sqrt(sum(r2)/nrow(fd.m25)))

rmse20hi <- broom::augment(test20) %>% 
  mutate(ws=`offset(ws * b_20)` * 5) %>% #get back to original ws
  filter(ws > 15) %>%
  select(.resid) %>% 
  mutate(r2 = .resid^2) %>% summarize(rmse=sqrt(sum(r2)/nrow(fd.m25)))
#rmse20hi == 1.21
#rmse25hi == 1.19; 25% model is better for higher ws values

#compare with intercept model M1:
rmseM1 <- broom::augment(m1.sf.lin.ws) %>% 
  select(.resid) %>% 
  mutate(r2 = .resid^2) %>% summarize(rmse=sqrt(sum(r2)/nrow(fd.m25)))

#rmseM1: 1.6
#rmse20: 1.62
#rmse25: 1.72


```

```{r label=m.25percent, echo=FALSE }

#get predictions for assigned function models:
#At this point, 65 obs from boreal conifer looks good
df.funs <- s.con %>%
#  fd.ros %>% filter(FiT2=='S') %>% 
  select(fire, ws, ISI, ROS) %>% 
  filter(!str_detect(fire, 'DEWDROP')) %>%
  mutate(num=row_number(),
         c3s = c3s(ISI),
         c4s=c4s(ISI),
         c6s=c6s(ISI),
         d1=d1(ISI),
         m25 = m25(ws)) %>%
  select(-c(fire, ws, ISI)) %>% select(num, everything()) #num then everything else


#spread data out for easy summarizing - used in Table 1
df.funs.longer <- tidyr::pivot_longer(df.funs, 
                                      cols=c(ROS, c3s, c4s, c6s, d1, m25), 
                                      names_to='model', values_to='value')

#Testing D1 vs deciduous fires
    # summarize(MAE=mae.manual(actual=df.funs$ROS, pred=value) %>% round(2),
    #           MAPE=mape.manual(actual=df.funs$ROS, pred=value) %>% round(2),
    #           ER2=ef.r.squared(actual=df.funs$ROS, pred=value) %>% round(2)

#Evaluation functions
load(file='./files/mae.rda')
load(file='./files/mape.rda')
load(file='./files/Efr2.rda')


s.dec <- s.fires.mod %>% filter(FT=='Decid') %>%
  mutate(d1=d1(ISI)) %>%
  select(num, fire, ISI, ROS, FT, d1)

s.dec.eval <- s.dec %>%
  summarize(MAE=mae.manual(actual=s.dec$ROS, pred=s.dec$d1) %>% round(3),
            MAPE=mape.manual(actual=s.dec$ROS, pred=s.dec$d1) %>% round(3),
            ER2=ef.r.squared(actual=s.dec$ROS, pred=s.dec$d1) %>% round(3))
#ok

fig2
```

*Caption: Figure 2. Overview of rate of spread (ROS) of conifer fires, including surface and crown fire observations by 10 m wind speed (WS~10~). Observations are organized by type of fire with fitted linear trends. S, PC, and AC refer to surface, passive crown, and active crown fire behaviour types, respectively. The black line represents the '25 % model' for surface fire behaviour:* 
$ROS=0.25 \times WS_{10} $ *(ROS in m/min; WS~10~ in km/h).*

Surface fire ROS ranged from 0.3 - 12.0 m min^-1^. In conifer stands, surface and passive crown fire observations overlapped for ROS \> \~4 m min^-1^ (Fig. 2), and most fires' sROS values were well below the maximum value (95th percentile sROS of `r quantile(filter(fd.ros, FiT2=='S')$ROS, 0.95)` m min^-1^.). The fitted linear trend shown in Fig 2 (green line) represents a very simple baseline linear surface ROS model for conifer observations (Model 1, n= `r fd.ros %>% filter(FiT2=='S') %>% nrow()` ; root mean squared error (RMSE)=1.60, adjusted *R^2^* = 0.319). Noting that the intercept was small ($\beta$=`r round(m1.int, 2)`) and the slope ($ \beta_1=0.2459$) very close to 0.25, a few simple  forced-intercept models were evaluated, as $ROS=\beta_1 \cdot WS_{10}$, with $\beta$ equal to 0.2 or 0.25. 

### Model evaluation and selection

The extensive search among possible predictor variables revealed *ISI* and *ISI~sa~* to be strong predictors of ROS, as expected. The best 1-5 variable sROS predictor combinations all contained one of these variables as linear or squared terms. In particular, *ISI^2^* or *ISI~sa~^2^* were the best single predictors, with *ISI^2^* slightly superior using the conifer-only dataset and *ISI~sa~^2^* best using the aggregated data from all forest types. The matrix of models and frequency of various predictors in the model search can be found in Appendix B.  

In addition to evaluation statistics, we chose the most promising final models based on variable significance, known properties of weather and fuel with respect to fire, and operational simplicity and utility for users. After the initial 'regsubsets' search with all variable predictors, terms that did not appear in any of the best 3 combinations were dropped from testing. Certain predictor combinations were also rejected for illogical behaviour or suspected multi-collinearity indicative of likely overfitting; for instance, models that included both *ISI* and *ISI~sa~* terms, or models that included either spread index along with *WS* or *FFMC*/*mc~SA~*, since the spread indices already incorporate both wind and  estimated litter moisture influences. At the end of the testing, a matrix of four main sROS model categories were sought: models for all forests and models for boreal/sub-boreal conifer forests exclusively; and models using the base FWI predictors (*FFMC*, *ISI*) vs those using the stand-adjusted format (*mc~sa~*, *ISI~sa~*). SFC was significant in some models (square root-transformed) as was Fuel Type (FT). Response functions were mostly forced through the origin due to the known lack of fire spread potential during low wind and high moisture conditions (e.g. ISI \< 2) and in order to produce models usable across a broad range of wildfire conditions (i.e., *ISI* or *ISI~sa~* values of 0–20 or higher).

Figure 3 shows sROS observations with fires classified by FT and SFC, displayed by *ISI*, overlaid with some exploratory fitted models along with the D-1 FBP model. While all fires were initially classed as surface fires in original sources, several observations appeared anomalous, including those with significant levels of canopy fuel consumption (CFC), suggesting canopy fuel involvement beyond what would constitute expected behaviour in an understory surface fire. Fires with estimated CFC \> 0.2 kg m^-2^ were then removed from the dataset in order to exclude fires considered transitional to crown fire. Figure 3 also shows a simple linear sROS model based on *ISI* (Model 2: RMSE=1.53; ER2=0.469), as well as the better-fitting quadratic model forced through the origin using *ISI^2^* (Model 3: RMSE=1.30; ER2=0.613).

### [Prep for fig3]

```{r label=PrepFig3, echo=FALSE}
#Show data, exceptions (CFC >0.1), PPDF orig. 
s.fires4 <- s.fires3 %>%
  mutate(
                 FT2=str_extract(ExpProject, "\\([^()]*\\)"), #all inside ()
                 FTsp=str_detect(FT2, 'S') %>% as.factor(), #T/F spruce
                 FT3=case_when(
                   str_detect(FT2, '/') ~ '2. S',  #mix of pine /spruce
                   str_detect(FT2, 'S') ~ '2. S',  #spruce only
                   str_detect(FT2, '(JP)') ~ '1. JP',         #jack pine only
                   str_detect(FT2, 'PPDF') ~ '5. PPDF',  #dewdrop ppdf
                   str_detect(FT2, 'D1') ~ '4. Decid', #D1 stands
                   str_detect(FT2, 'P') ~ '3. OP') %>% #should cover other pines
    as.factor())


#asymtote function - not used; see 'slope asymptote' section below
# asym <- function(isi) {
#   0.33333*isi #ROS 10 at ISI 30
# }

```

### [slope asymtote CR models]

```{r label=slopeAsymtote, echo=FALSE}

#make asymtote as linear function
#For aggregate 'level off' (CR) model, Should cross ROS=20 at around ISI=65
#very similar to current sf.crisi.fun(65)
#combine that with a shallow slope, say 0.15

#Aggregate data models
asy.slope1 <- 0.15 #m
asy.yInt1 <- 10 #i

asym1 <- function(isi) {
  asy.slope1*isi +asy.yInt1
}

#m10: slope asymptote, aggregate data, ISI
#m11: sl asy, agg data, ISI_sa
#m12: sl asy, con data, ISI
#m13: sl asy, con data, ISI_sa
#m14: pow model, agg data, mc_FFMC
#m15: pow, agg data, mc_sa
#m16: pow, con data, mc_FFMC
#m17: pow, con data, mc_sa
#m18: FT model - whatever's best

# New Aggregate CR equation with slope asymptote
m10.agISI <- nls(data=s.fires.mod, formula= #substitute for sf.crisi.mod
               ROS ~ (asy.slope1 * ISI + asy.yInt1) * (1-exp(-b*ISI))^c,
               start=list(b=0.1, c=3))

#fitted asymptote? Nope
# sf.agg.asyfit<- nls(data=s.fires.mod, formula= #substitute for sf.crisi.mod
#                ROS ~ (m1 * ISI + asy.yInt1) * (1-exp(-b*ISI))^c, 
#                start=list(b=0.1, c=3, m1=0.15))
##fitted m and i didn't converge; fitted m1 gave NS model, with m1=~0.22


fun.m10 <- function(isi) {  #substitute for sf.crisi.fun; was M10
  predict(m10.agISI, newdata=list(ISI=isi))
}

#exploratory graph to show that this works - asymptote graph, aggregate data, ISI
ag <- ggplot(s.fires4, aes(x=ISI, y=ROS)) + 
  geom_point() + 
  stat_function(fun=fun.m10, xlim=c(0, 70), colour='green') + 
  stat_function(fun=sf.crisi.fun, xlim=c(0, 70), colour='black') +
  stat_function(fun=asym1, xlim=c(0, 70), colour='blue') +
  coord_cartesian(ylim=c(0, 25))

#yessss!!

#Conifer, ISI
#For start, use same asymptote as Aggregate model- no, shift upwards a bit
asy.slope2 <-0.15
asy.yInt2 <-13

#New Conifer model with slope asymptote
m12.conISI <-nls(data=s.con, formula=
                 ROS ~ (asy.slope2 * ISI + asy.yInt2) * (1-exp(-b*ISI))^c,
                 start=list(b=0.1, c=3))

#fitted asymptote?
# sf.con.asyfit <-nls(data=s.con, formula=
#                  ROS ~ (asy.slope2 * ISI + i2) * (1-exp(-b*ISI))^c,
#                  start=list(b=0.1, c=3, i2=13))
#did not converge/infinity produced

#prediction function
fun.m12 <- function(isi) {  #substitute for sf.crisiCon.fun; M13
  predict(m12.conISI, newdata=list(ISI=isi))
}

asym2 <- function(isi) {
  asy.slope2*isi +asy.yInt2
}

#Exploratory asymptote graph
ag2 <- ggplot(s.con, aes(x=ISI, y=ROS)) + 
  geom_point() + 
  stat_function(fun=fun.m12, xlim=c(0, 70), colour='green4') + 
  stat_function(fun=sf.crisiCon.fun, xlim=c(0, 70), colour='gray4') +
  stat_function(fun=asym2, xlim=c(0, 70), colour='blue') +
  coord_cartesian(ylim=c(0, 25))

#ISI.mcsa - Aggregate; same asymptote to start with
asy.slope3 <- 0.15
asy.yInt3 <- 10

asym3 <- function(isi.m) {
  asy.slope3*isi.m +asy.yInt3
}

# New Aggregate CR equation with slope asymptote
m11.agSa<- nls(data=s.fires.mod, formula= #substitute for sf.crisim.mod
               ROS ~ (asy.slope3 * isi.m + asy.yInt3) * (1-exp(-b*isi.m))^c, 
               start=list(b=0.1, c=3))

#fitted asymptote?
# sf.aggM.asyfit<- nls(data=s.fires.mod, formula= #substitute for sf.crisim.mod
#                ROS ~ (asy.slope3 * isi.m + i3) * (1-exp(-b*isi.m))^c, 
#                start=list(b=0.1, c=3, i3=10))
#did not converge/infitity produced when fitting m3 or i3

fun.m11 <- function(isi.m) {  #substitute for sf.crisi.fun; M10
  predict(m11.agSa, newdata=list(isi.m=isi.m))
}

ag3 <- ggplot(s.fires4, aes(x=isi.m, y=ROS)) + 
  geom_point() + 
  stat_function(fun=fun.m11, xlim=c(0, 70), colour='green4') + 
  stat_function(fun=sf.crisim.fun, xlim=c(0, 70), colour='gray6') +
  stat_function(fun=asym3, xlim=c(0, 70), colour='blue3') +
  coord_cartesian(ylim=c(0, 30))


#ISI.mcsa - Conifer
asy.slope4 <-0.15
asy.yInt4 <-13

#New Conifer model with slope asymptote
m13.conSa <-nls(data=s.con, formula=
                 ROS ~ (asy.slope4 * isi.m + asy.yInt4) * (1-exp(-b*isi.m))^c,
                 start=list(b=0.1, c=3))

#prediction function
fun.m13 <- function(isi.m) {  #substitute for sf.crisiCon.fun; M13
  predict(m13.conSa, newdata=data.frame(isi.m=isi.m))
}

asym4 <- function(isi.m) {
  asy.slope4*isi.m +asy.yInt4
}


#Fernandes-type power law models: m14 through m17
#Aggregate data
m14.power.full <-nls(data=s.fires.mod2, formula=
  ROS ~ a * ws^b * exp(c*MC.FFMC), start=list(a=1, b=1, c=-0.05))

m15.power.safull <-nls(data=s.fires.mod, formula=
  ROS ~ a * ws^b * exp(c*MC.SA), start=list(a=1, b=1, c=-0.05))

#con models
m16.power <-nls(data=s.con, formula=
  ROS ~ a * ws^b * exp(c*MC.FFMC), start=list(a=1, b=1, c=-0.05))

#with mcsa:
m17.power.sa <-nls(data=s.con, formula=
  ROS ~ a * ws^b * exp(c*MC.SA), start=list(a=1, b=1, c=-0.05))
#better than sloped asy model

#functions
#m17 - mcsa/ISIsa
fun.powersa <- function(ws, mcsa=10) {
  isim=isi.mcsa(mcsa=mcsa, ws=ws)
  rosi=predict(m17.power.sa, newdata=data.frame(ws=ws, MC.SA=mcsa))
  return(rosi)
}

#m16 - mc/ISI
fun.power <- function(ws, ffmc=90) {
  isi=ISI(ws=ws, ffmc=ffmc)
  rosi=predict(m16.power, 
               newdata=data.frame(ws=ws, MC.FFMC=mcF(ffmc)))
  return(rosi)             
}

#power models use both ws and mc, so to show them in an ISI or ISI_sa graph, 
#you need to fix the mc (or ws) and calculate ISI first
#NOt perfect - predicted ROS will vary by mc too, but ok for graphing

#calc sf.powersa by ISI for mc=9 (mean value is FFMC 90.4)
wind.range <- seq(0, 60, by=0.5)
wind.range2 <- seq(0, 20, by=0.5)
wind.range3 <- seq(0, 10, by=0.5)
mc.power <- 9
mc.power2 <- 13
mc.power3 <- 17
#for ISI model m16
ffmc.power <- 91.7
ffmc.power2 <- 88
ffmc.power3 <- 84.4
ROS.powersa.points <- fun.powersa(
  ws=wind.range, mcsa=mc.power) #ROS using power model
ROS.powersa.points2 <- fun.powersa( #for low range
  ws=wind.range2, mcsa=mc.power2)
ROS.powersa.points3 <- fun.powersa(
  ws=wind.range3, mcsa=mc.power3)
isim.powersa.points <- isi.mcsa(
  ws=wind.range, mcsa=mc.power) #ISI_sa using fixed mc of 9
isim.powersa.points2 <- isi.mcsa(
  ws=wind.range2, mcsa=mc.power2)
isim.powersa.points3 <- isi.mcsa(
  ws=wind.range3, mcsa=mc.power3)

#now I can graph these two
powersa.df <- data.frame(ROS=ROS.powersa.points,
                       isi.m=isim.powersa.points)

powersa2.df <- data.frame(ROS=ROS.powersa.points2, 
                        isi.m=isim.powersa.points2)

powersa3.df <- data.frame(ROS=ROS.powersa.points3,
                        isi.m=isim.powersa.points3)

powersacon.df <- bind_rows(powersa.df, powersa2.df, powersa3.df)

#Exploratory asymptote graph - conifer, ISI.m
#Maybe Fig 5?
ag4 <- ggplot(s.con, aes(x=isi.m, y=ROS)) + 
  geom_point() + 
#  geom_point(data=power.df, colour='red') + 
  stat_smooth(data=powercon.df, colour='red') +
  stat_function(fun=fun.m13, xlim=c(0, 60), colour='gray5') + #sl.asy
  stat_function(fun=fun.m4, xlim=c(0, 60), colour='blue') + #fixed
  #stat_function(fun=sf.powersa, xlim=c(0, 70), colour='red')+ #power func
  stat_function(fun=asym4, xlim=c(0, 60), 
                colour='gray', linetype='dashed') + #asymptote
  coord_cartesian(ylim=c(0, 30), xlim=c(0, 60))


#with FT
#+     aP*FT_P + aD*FT_D, start=list(b=0.1, c=3, aP=0, aD=0))
s.power.FT <-nls(data=s.fires.mod2, formula=
  ROS ~ a * ws^b * exp(c*MC.SA) +
  aP*FT_P + aD*FT_D, 
  start=list(a=1, b=1, c=-0.05, aP=0, aD=0))
#ft factors NS (biggest dif is about ROS 0.6 m/min higher for PPDF than con)
#Nope - stick with slope asymptote for m18 FT model




#####

# s.pow.eval <-s.con %>%  #new m15 is Conifer mod with ISIsa
#   mutate(spowsa =predict(m15.power.sa, newdata=data.frame(ws=s.con$ws,
#                           MC.SA=s.con$MC.SA))) %>%
#   summarize(MAE=mae.manual(actual=ROS, pred=spowsa) %>% round(3),
#             MAPE=mape.manual(actual=ROS, pred=spowsa) %>% round(3),
#             ER2=ef.r.squared(actual=ROS, pred=spowsa) %>% round(3))
# 
# s.powAg.eval <- s.fires.mod %>%  #new m13, mc.sa model full data
#   mutate(spowsa =predict(m13.power.safull, newdata=data.frame(ws=s.fires.mod$ws,
#                           MC.SA=s.fires.mod$MC.SA))) %>%
#   summarize(MAE=mae.manual(actual=ROS, pred=spowsa) %>% round(3),
#             MAPE=mape.manual(actual=ROS, pred=spowsa) %>% round(3),
#             ER2=ef.r.squared(actual=ROS, pred=spowsa) %>% round(3))
# #MAE:1.035, MAPE: 0.65; ER2: 0.601; AIC:330
# #Very similar to slope asymptote model with ISI_sa, which has slightly lower AIC
# 
# s.powFul.eval <- s.fires.mod2 %>%  #full data, FFMC model
#   mutate(spow.pr =predict(m12.power.full, newdata=data.frame(ws=s.fires.mod2$ws,
#                           MC.FFMC=s.fires.mod2$MC.FFMC))) %>%
#   summarize(MAE=mae.manual(actual=ROS, pred=spow.pr) %>% round(3),
#             MAPE=mape.manual(actual=ROS, pred=spow.pr) %>% round(3),
#             ER2=ef.r.squared(actual=ROS, pred=spow.pr) %>% round(3))

# I think all the s.pow models are better than the slope asymptote ones...
#only exception is ISI.sa full data one...


```

### [Fig3]

```{r label=Fig3, echo=FALSE}
est.sfc2 <- s.fires4 %>% filter(is.na(SFC)==TRUE) %>%
  mutate(SFC=1) #overall mean SFC is 0.991


Fig3 <- ggplot(s.fires4 %>% 
                 filter(!is.na(SFC)), 
       aes(x=ISI, y=ROS)) +  
  scale_fill_manual(values=c(
    'red3',
    'orange2',
    'yellow3', 
    'darkgreen',
    'turquoise4',
    'darkorchid4')) +
  scale_colour_manual(values=c(
    'red3',
    'orange2',
    'yellow3', 
    'darkgreen',
    'turquoise4',
    'darkorchid4')) +
  geom_point(aes(fill=FT3, colour=FT3, size=SFC), 
             alpha=0.6, shape=21) + #main fires    
  geom_point(data=est.sfc2, aes(fill=FT3, size=SFC), shape=21, 
             colour='black', alpha=0.5) + #show fires with est. SFC (blk rim)
  geom_point(data=except, aes(colour=FT), size=2, shape=22) + #torching
  geom_point(data=wildfires, colour='black', fill='black', size=1, 
             shape=21) + #wildfires
#  geom_point(data=ppdf, aes(size=SFC), shape=21) +
  stat_smooth(data=s.fires.con, method=lm, formula=y~I(x^2)-1, 
              se=FALSE, colour='black') + #same as sros.isi2.mod   
  stat_smooth(data=s.fires.con, method=lm, 
              formula=y~x, se=FALSE, colour='gray') + #linear fit
  stat_function(fun=d1, colour='green3', linewidth=1) +
  coord_cartesian(xlim=c(0, 30), ylim=c(0, 17)) +
  theme_bw() +
  scale_y_continuous(breaks=seq(0, 16, by=4),
                     minor_breaks=seq(0, 16, by=2)) +
  scale_x_continuous(breaks=seq(0, 30, by=5)) +
  guides(fill=guide_legend(order=1),
         size=guide_legend(order=2), 
         colour='none') +
  theme(legend.position =  'inside', 
        legend.position.inside= c(0.02, 0.7),
        legend.justification = c(0, 0.5),
        legend.box = 'horizontal',
        legend.background = element_rect(fill='grey85')) +
  labs(y='ROS (m/min)', fill='Fuel Type')
  
  
Fig3


m2.sf.lin.isi <- lm(ROS~ISI, data=s.fires.con)
#linear ISI model like in graph



```

*Caption: Figure 3. Fire observations showing rate of spread (ROS) by ISI and initial model fitting. Most symbols represent experimental fires except those with a black centre are wildfires. Colours indicate fuel type and fire characteristics as follows: JP: jack pine; S: black spruce or pine-spruce mix; OP: other pine; Decid: deciduous; PPDF: Ponderosa pine-Douglas-fir. Squares represent fires with crown fuel consumption > 0.2 kg m^-2^, therefore questionable as true surface fires (removed from most sROS models). SFC indicates surface fuel consumption (kg m^-2^). Observations with no measured SFC have a black outline and are plotted with the mean overall SFC value (1.0 kg m^-2^). The lines represent linear (Model 2: gray) and quadratic (Model 3: black) ISI models fitted to conifer observations (JP, S, OP), along with the FBP D-1 model (green).*

### [DewdropWFC]

```{r label=DewdropLargeWFC, echo=FALSE, warnings=FALSE}
#difference between Stocks' sites and Dewdrop:
stockssfc <- filter(fd.all, num %in% c(sharp, kenshoe)) %>%
  filter(num !=40 & num !=24) %>% pull(SFC)

stocks.lwfc <- c(
0.049,
0.042,
0.086,
0,
0.047,
0.01,
0,
0,
0.231,
0.045,
0.074,
0.132, #end Kenshoe
  0.037,
0.024,
0.047,
0.085,
0.259,
0.153,
0.345,
#0.345,  #no duplicating p11
0.34,
0.374,
0.488,
0.061,
0.223  #end sharpsand
)

#large WFC proportion
stocks.prop <- stocks.lwfc/stockssfc

#Dewdrop burns - need to add 
dewdrop.lwfc <- c(
1.139,
0.061,
0.681,
1.545,
0.693,
2.188,
3.892
)

dewdropsfc <- filter(fd.all, num %in% dewdrop) %>%
  filter(num !=120)  %>% #filter out 1980 burn, no info
  pull(SFC) + dewdrop.lwfc

#large wfc proportion
dewdrop.prop <- dewdrop.lwfc/dewdropsfc

#Wilcoxon rank-sum test (Mann-Whitney U-test)
prop.data <- data.frame(LWFC.prop=c(
  stocks.prop, dewdrop.prop),
            site=as.factor(
            c(rep(1, times=length(stocks.prop)),
              rep(2, times=length(dewdrop.prop)))))
                        
# wilcox.result <- prop.data %>%
  # with(wilcox.test(LWFC.prop ~ site)) 
# W=9, p-value=0.0004296
                                       
                                       
```

FT differences in the aggregate data were significant between all contrasts of conifer, deciduous, and PPDF fuels (Tukey HSD: α=0.05), with deciduous \< conifer \< PPDF in terms of main effects model ROS classes. Within the conifer-only dataset, FT was defined differently: in addition to 6 spruce observations, there were 19 fires in jack pine (JP), and 26 in stands dominated by other pine species (OP), primarily red pine (*P. resinosa*). From the conifer dataset, the only significant contrast was between OP and JP, with OP fires exhibiting slightly slower ROS compared with JP fires (Fig. 3).

While SFC did not initially stand out as significant, it was explored further due to its perceived usefulness. The best combinations appeared to be with the sqrt(SFC) predictor together with *ISI^2^* or *ISI~sa~^2^*. Most model forms using \> 2 predictors were non-significant (α=0.05) due to small sample size and high variability. Density class was initially flagged as potentially significant, but was then dropped due to confounding behaviour with the *ISI~sa~* (Appendix C).

### [Table 1: Model summary]

```{r ModSumTable, echo=FALSE, warning=FALSE}
#Model list

#New CR replacements
#sf.agg.asy - aggregate, ISI
#sf.con.asy - conifer, ISI
#sf.aggM.asy - aggregate, isi.m
#sf.ConM.asy - conifer, isi.m


#add sros.st, 
mod.list.long <- list(m1.sf.lin.ws, #m1 keep
              m2.sf.lin.isi, #m2
              m3.con.ISI.mod, #m3 keep
              m4.con.lm.mod, #m4
              m5.sros.ws2.mod, #m5
              m6.sros.ISI2.mod, #m6 keep
              m7.sros.ISI2SFC.mod, #m7 
              m8.sros.isim2.mod, #m8
              m9.sros.isim2SFC.mod, #m9 keep
              m10.agISI, #keep
              m11.agSa, #keep
              m12.conISI, #k
              m13.conSa, #k
              m14.power.full, #
              m15.power.safull, #
              m16.power, #k best overall
              m17.power.sa,
              m18.agAsy.FT, #k
        #       m10.sf.agg.asy,  #slope asymptote model, aggregate ISI
        # #      sf.crisi.mod,
        #       m11.sf.aggM.asy, #slope asymptote for aggregate, isi.m
        # #      sf.crisim.mod,  #
        #       #m12.sf.axb.isi.mod, 
        #       m12.power.full, #Ag data, needs ws, MC.FFMC inputs
        #       m13.power.safull, #Ag data, mcsa model
        #       m14.power, #Con data, ws, FFMC
        #       m15.power.sa, #Con data, mcsa model
        #       m16bXX, #new slope-asymptote Fuel Type model
              c3s,
              c4s, 
              c6s,
              d1,
              m25) #keep

# m12.power.full 
# m13.power.safull 
# m14.power 
# m15.power.sa 


modnames <-c('wslin.con',
             'isilin.con',
             'ISI2.con',
              'isim2.con',
              'WS2.agg',
              'ISI2.agg',
              'ISI2SFC.agg',
              'isim2.agg',
              'isim2SFC.agg', #m9
             'sl.agg.ISI', #m10
             'sl.agg.isim', #m11
             'sl.con.ISI', #m12
             'sl.con.isim', #m13
             'pow.agg.ISI', #m14
             'pow.agg.isim', #m15
             'pow.con.ISI', #m16
             'pow.con.isim', #m17
             'sl.ag.FT', #m18
             #  'crisi.asy.agg', #replaces crisi.agg m10
             #  'crisim.asy.agg', #replaces crisim.agg m11
             #  'pow.full.ffmc', # m12.power
             #  'pow.fullSa',  #m13 power
             #  'power.con', #m14 power
             # 'power.conSa', #m15 power
             # 'FTaggAsy', #m16 Ag asy FT
             'c3s', 'c4s', 'c6s', 'd1', '25 perc') #last 5 are functions

#models only (not functions)
mod.list <- mod.list.long[1:(length(mod.list.long)-5)]

#formulae from model list
formulae0 <- lapply(mod.list, FUN=formula) %>% 
  as.character() %>%
  str_extract(pattern="~(.*)") %>% #keep everything right of the tilde
  str_remove('~ ') 

#edit formula strings
process_string <- function(s) {
  if (str_ends(s, "- 1")) { # Remove "- 1" from the end
    return(str_remove(s, "- 1$"))
  } else {
    if(str_ends(s, '\\^c') | str_ends(s, '\\^b'))
       {return(s)} else {
    return(str_c("b0 +", s))      # Add "b0 +" to the beginning
  }}
}

formulae <- sapply(formulae0, process_string) %>% unname() %>%
   #get ride of the tilde
  append(c(  #add the manual and Van Wagner models at the end
    'C-3s', #c3s
    'C-4s', #c4s
    'C-6s', #c6s
    'D-1', #d1
    '25 % WS_10')) %>% #m25 model
  str_replace_all('I\\(ISI\\^2\\)', 'ISI2') %>%  #clean up squared terms
  str_replace_all('I\\(isi.m\\^2\\)', 'ISIsa2') %>%
  str_replace_all('I\\(ws\\^2\\)', 'WS2') %>%
  str_replace_all('\\(asy[^)]*\\)', 'SlAsy') %>%
  # str_replace_all('a.value', str_c('Asy', as.character(a.value))) %>%
  # str_replace('b0 \\+Sl', 'Sl') %>% #fix extraneous  b0 term for m12
  str_replace_all('isi.m', 'ISIsa')

#generate table of evaluation metrics
#MAE, MAPE, RMSE
acc.table2 <- rcompanion::accuracy(mod.list) %>% 
  as.data.frame() %>%
  mutate(num=1:length(mod.list))

#get AIC, num of obs - repeat glance function across all models
acc.glance <- lapply(mod.list, broom::glance)

#pull nobs and AIC from glance operation
acc.glance2 <- lapply(acc.glance, `[`, c('nobs', 'AIC' )) %>%
  list_rbind() %>% round(1) %>%
  mutate(num=1:length(acc.glance))

#metrics for pre-determined model functions:
#mae.manual(actual=df.m25$ROS, pred=df.m25$pred25) # etc.
# load(file='./files/mae.rda')
# load(file='./files/mape.rda')
# load(file='./files/Efr2.rda')

#calculate some metrics for m25 and the FBP model functions:
#FBP/VW models
df.eval <- df.funs.longer %>% group_by(model) %>%
    summarize(MAE=mae.manual(actual=df.funs$ROS, pred=value) %>% round(3),
              MAPE=mape.manual(actual=df.funs$ROS, pred=value) %>% round(3),
              ER2=ef.r.squared(actual=df.funs$ROS, pred=value) %>% round(3)
              ) %>%
  filter(model != 'ROS') %>%
  mutate(num=(length(mod.list)+1):(length(mod.list)+5),nobs=NA, RMSE=NA) %>%
  rename(Model=model)

#combine the two column groups, two evaluation tables, clean up
acc.table3 <- left_join(acc.glance2, acc.table2, 
                        by='num') %>%
  mutate(Model=modnames[1:(length(modnames)-5)]) %>%
  rename(MAE=Fit.criteria.MAE,
         MAPE=Fit.criteria.MAPE,
         RMSE=Fit.criteria.RMSE,
         ER2=Fit.criteria.Efron.r.squared
        ) %>%
  select(num, Model, nobs, RMSE, MAE, MAPE, ER2, AIC) %>%
  #add FBP and m25 metrics
  bind_rows(df.eval)

#evaluate D1 with decid observations
#replace MAE, MAPE, ER2 values with decid values (see Model eval; s.dec.eval)
acc.table3[which(acc.table3$Model=='d1'), 5:7] <- s.dec.eval

#ROS table at ISI (ISIm)=5, 10, 15
isi.vals=c(5, 10, 15)
ffmc.val=91
ws.vals=c(1, 14, 22)
mod.order.isim<- c(1, 4, 7, 10)
mcsa.val=9.78

#Predict ISI values with all final models
#create blank list
pred.list <- vector('list', length(mod.list))
names(pred.list) <- modnames[1:(length(modnames)-5)]

#loop to predict ROS
#data.frame needs to include all possible predictors
for (i in seq_along(mod.list)) {  #predict all mods in mod.list
  pred.list[[i]] <- predict(mod.list[[i]], 
                            newdata=
                              data.frame(ISI=isi.vals,
                                        isi.m=isi.vals,
                                        FFMC=ffmc.val,
                                            MC.FFMC=mcF(ffmc.val),
                                        MC.SA=mcsa.val,
                                        ws=ws.vals,
                                        SFC=1,
                                        FT_P=0,
                                        FT_D=0))
}

pred.df <- data.frame(ISI=isi.vals, pred.list) %>%
  mutate_all(round, 1)

#transpose
pred2.df <- as.matrix(pred.df) %>% 
  t() %>% as.data.frame() %>%
  mutate(Model=colnames(pred.df)) %>%
  slice(2:ncol(pred.df)) %>%
  select(Model, everything())

row.names(pred2.df) <- NULL
isi.colnames <- c('ISI=5', 'ISI=10', 'ISI=15' ) 
colnames(pred2.df)[2:4] <- isi.colnames

#get c6, c4s, c3s d1 predictions
#ws vals at FFMC 91: 0.2162, 13.972, 22.019 for m25 model
ws.vals <- c(0.2162, 13.972, 22.019)

#predict ROS at 5, 10, 15 for FBP models, 25% model
v1 <- c3s(isi.vals)
v2 <- c4s(isi.vals)
v3 <- c6s(isi.vals)
v4 <- d1(isi.vals)
v5 <- m25(ws.vals)

#transpose
v15vals <- data.frame(v1, v2, v3, v4, v5) %>%
  as.matrix %>% t() %>%
  as.data.frame()

#A lot of effort to make a table of predictions at 3 values, but it works
predAdd.df <- data.frame(Model=df.eval$Model, 
                         ISI.5=v15vals[,1] %>% round(1),
                         ISI.10=v15vals[,2] %>% round(1),
                         ISI.15=v15vals[,3] %>% round(1))
colnames(predAdd.df) <- c('Model', isi.colnames)

#combine sROS models, FBP models
pred3.df <- rbind(pred2.df, predAdd.df)

acc.tab4 <- left_join(pred3.df, acc.table3, by='Model') %>%
  mutate(Num=1:max(nrow(pred3.df), nrow(acc.table3)),
         Formula=formulae) %>%
  select(Num, Model, Formula, N=nobs, everything(), -num)

######################
#write.csv(acc.tab4, 'acc_table.csv')

#acc.tab4

#generate formatted table using gt
require(gt)

tab1.full <-
acc.tab4 %>% select(-Model) %>%
  #mutate(Formula = if_else(row_number() <= 9, 
  #                         map_chr(Formula, format_formula), 
  #                         Formula)) %>%
  gt() %>%
  tab_header(
    title = "Table 1" #,
#    subtitle = "Your subtitle (if needed)"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  cols_width(
    Num ~ px(50),
    Formula ~ px(100),
    everything() ~ px(60)
  ) %>%
  tab_spanner(
    label='Predicted ROS (m/min)',
    columns=4:6
  ) %>%
  tab_spanner(
    label='Evaluation metrics',
    columns=7:11
  ) %>%
  tab_style(
    style = cell_borders(
      sides = 'bottom',
      color = "black",
      weight = px(1)
    ),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    table.width = pct(100),
    column_labels.border.top.width = 2,
    column_labels.border.top.color = "black",
    column_labels.border.bottom.width = 2,
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table.border.bottom.width = 2,
    data_row.padding = px(3),
    column_labels.border.bottom.style = 'none',
    table_body.hlines.color = 'white'
  ) %>%
  opt_horizontal_padding(scale = 0.5) %>%
  opt_vertical_padding(scale = 0.5) %>%
  tab_source_note(
    source_note = "Your source note or additional information here"
  ) %>%
  opt_table_font(font = "Arial") #%>% gtsave("your_table.html")

#tab1.full

#shorter table - only the better models for main paper
acc.tab.short <-
  acc.tab4 %>% select(-Model) %>%
  filter(Num %in% c(1, 3, 6, 9, 10:13, 16, 18:23)) 

tab1.short <-
  acc.tab.short %>%
  gt() %>%
  tab_header(
    title = "Table 1" #,
#    subtitle = "Your subtitle (if needed)"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  cols_width(
    Num ~ px(50),
    Formula ~ px(100),
    everything() ~ px(60)
  ) %>%
  tab_spanner(
    label='Predicted ROS (m/min)',
    columns=4:6
  ) %>%
  tab_spanner(
    label='Evaluation metrics',
    columns=7:11
  ) %>%
  tab_style(
    style = cell_borders(
      sides = 'bottom',
      color = "black",
      weight = px(1)
    ),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    table.width = pct(100),
    column_labels.border.top.width = 2,
    column_labels.border.top.color = "black",
    column_labels.border.bottom.width = 2,
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table.border.bottom.width = 2,
    data_row.padding = px(3),
    column_labels.border.bottom.style = 'none',
    table_body.hlines.color = 'white'
  ) %>%
  opt_horizontal_padding(scale = 0.5) %>%
  opt_vertical_padding(scale = 0.5) %>%
  tab_source_note(
    source_note = "Your source note or additional information here"
  ) %>%
  opt_table_font(font = "Arial") #%>% gtsave("your_table.html")
  
tab1.short

```

*Caption: Table 1. Model forms and evaluation metrics for the fitted sROS models, in order of increasing complexity. Formulae include variables representing 10-metre wind speed (WS~10~), initial spread index (ISI), stand-adjusted ISI (ISI~sa~), surface fuel consumption (SFC, kg m^-2^), litter moisture content (mc), as estimated from the Fine Fuel Moisture Code (mc~FFMC~) and stand-adjusted model (mc~sa~), and fuel type (FT). ISI columns represent predicted ROS (m min^-1^) for given models at each predictor level, representing the base ISI (or FFMC and wind speed) or ISI~sa~, depending on model form. Constants used in prediction calculations include FFMC 91 (Models 1, 5, 21), SFC of 1.0 kg m^-2^ (Models 7 and 9), and 'conifer' fuel type (Model 16). Evaluation metrics are unitless and include root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), Efron's R-squared (ER2), and Akaike's Information Criterion (AIC). The predefined functions (not fitted) consist of the C-3S, C-4S, C-6S, and M25 models, which were evaluated against the 51 boreal conifer surface fire observations; the D-1 model was evaluated against 32 deciduous observations.*

```{r ISIpreds, echo=FALSE}
#summary of ISI 5-15 vals
acc.extract<- filter(acc.tab4, !Num %in% c(19:22)) %>% #excl FBP models
  select('ISI=5', 'ISI=10', 'ISI=15') %>% round(2)

min5 <- acc.extract %>% pull('ISI=5') %>% min()
max5 <- acc.extract %>% pull('ISI=5') %>% max()
mean5 <-acc.extract %>% pull('ISI=5') %>% mean() 

min10 <- acc.extract %>% pull('ISI=10') %>% min()
max10 <- acc.extract %>% pull('ISI=10') %>% max()
mean10 <-acc.extract %>% pull('ISI=10') %>% mean() 

min15 <- acc.extract %>% pull('ISI=15') %>% min()
max15 <- acc.extract %>% pull('ISI=15') %>% max()
mean15 <-acc.extract %>% pull('ISI=15') %>% mean()

```

### Final fitted models

Table 1 shows evaluation metrics for a partial list of fitted models, as well as *ROS* predictions at three levels of *ISI* or *ISI~sa~* for comparison. Other variables (FFMC, SFC, FT) were assigned values where required for calculation purposes, as noted. The number of observations used (N) varied from `r min(acc.tab4$N, na.rm=T)` to `r max(acc.tab4$N, na.rm=T)`. Models using the SFC predictor excluded observations without estimated SFC, resulting in slightly smaller datasets. Model 1 used all conifer and PPDF observations (N=65), while other models used either the 'Aggregated' dataset (N=80-91), including all fires in boreal conifer, deciduous-mixed, and PPDF stands; or the 'boreal conifer' dataset (N=51-56), using only fires in spruce, pine-spruce, or boreal/sub-boreal pine stands (for most site and experimental descriptions see [@perrakis2023], Supplemental Material). Model 3 included all observations originally classed as surface fires, while models 6–18 excluded fires with significant crown fuel consumption, as noted. Excluding the FBP and CEVW models (19–22), *ISI* or *ISI~sa~* values of 5, 10, and 15 conditions predict ROS of `r min5` – `r max5` (mean: `r mean5`) m min^-1^; `r min10` – `r max10` (mean: `r mean10`) m min^-1^; and `r min15` – `r max15` (mean: `r mean15`) m min^-1^, respectively. Models forms using the boreal conifer observations (models 1, 3, 12-16) had lower variability and thus better performance (lower RMSE, higher ER2, lower MAE and MAPE) than analogous models fitted to the larger aggregated dataset.

The best models based on the evaluation diagnostics varied depending on dataset (conifer vs. aggregated) and the range of input variables. Simple and relatively high performing models were obtained using the *ISI^2* alone, though with much better performance (higher ER2, lower MAE, AIC and other error measures) using the conifer (m3) than the aggregated (m6) datasets. Non-linear model forms using Eq. 1 or 4 were unable to automatically fit the asymptote parameters, so visual inspection was used to estimate asymptotes (*m*=0.15, *i~agg~*=10, *i~con~*=13, for aggregate and conifer data, respectively). These allowed for fitting of relatively high-performing models for the aggregated and conifer datasets (m10-11, m12-13). The best performance overall across the range of data was achieved by the  models with separate wind and litter moisture inputs (e.g. m16: ER2=0.803, AIC=145.2). For the aggregated dataset models (6-18), performance improved when SFC or FT were included as predictors compared with using only ISI or ws and mc.   

Table 1 also compares ROS predictions for conifer stands from the CEVW and FBP surface fire functions, as well as the M25% model, with the new fitted models. High MAE and MAPE values, and negative values for ER2, suggest very poor performance by (especially) the C-4s and C-6s models compared to the fire observations. The C-3s, D1, and M25% models, in contrast, are in the lower end of the range of model performance, but otherwise appear to produce unbiased results. When evaluated against the deciduous data alone, the D-1 model had the following diagnostics: RMSE=0.568; MAE=1.297; MAPE=0.988; ER2=0.543.[^1] 

As for the simple forced-intercept wind speed model (Fig. 2), the best overall fit was with \beta~1~ of 0.2, with RMSE=1.62. However, at higher wind speed values, \beta~1~ of 0.25 was marginally superior (RMSE=1.19) than \beta~1~ of 0.2 (RMSE=1.21). The '25%' model therefore uses 1.5% of the 10-m wind speed alone using identical units (e.g. m s^-1^), or 25% of the 10-m wind speed in km h^-1^ to give sROS in m min^-1^ (e.g., ws of 20 km h^-1^ yields estimated ROS of 4 m min^-1^).

[^1]: Note: the dataset for the D-1 model originally described by [@forestrycanadafiredangergroup1992] differs only from present deciduous database by two additional wildfires, excluded here due to a lack of documentation.

### [Table A3: Extended SFC prediction calcs]

```{r Table A3, echo=FALSE}
#
#extra table for SFC-based models
multiv.names <- c(rep(c('ISI2SFC.agg', 'isim2SFC.agg'), each=4), rep('ftISI', 3))
sfc.levels <- c(0.7, 1.5, 3, 5)
ftd.levels <- c(1, 0, 0) #decid, con, ppdf
ftp.levels <- c(0, 0, 1)

#sf.isi2sfc.fun and sf.isim2sfc.fun - calc ROS for 3 ISI vals, 4 SFC vals
sfc.isivals <- mapply(FUN=sf.isi2sfc.fun, isi=rep(isi.vals, 4), 
                 sfc=rep(sfc.levels, each=3)) %>%
  matrix(nrow=4, ncol=3, byrow=TRUE) %>%  #calculate ROS for each
  as.data.frame() 
colnames(sfc.isivals) <- isi.colnames

sfc.isimvals <- mapply(FUN=sf.isim2sfc.fun, #apply sf.isim2sfc function across isi.vals
                       isim=rep(isi.vals,4),
                sfc=rep(sfc.levels, each=3)) %>%
  matrix(nrow=4, ncol=3, byrow=TRUE) %>%
  as.data.frame()
colnames(sfc.isimvals) <- isi.colnames

#Fuel type model: 
ftisi.vals <- mapply(FUN=fun.m18, #apply FT model across isi.vals
                       isi=rep(isi.vals, 3),
                ftd=rep(ftd.levels, each=3),
                ftp=rep(ftp.levels, each=3)) %>%
  matrix(nrow=3, ncol=3, byrow=TRUE) %>%
  as.data.frame()
colnames(ftisi.vals) <- isi.colnames

#combine df for both models
sfc.allvals <- rbind(sfc.isivals, sfc.isimvals, ftisi.vals) %>%
  round(2)

ex.sfc.tab <- mutate(sfc.allvals, 
                     Model=multiv.names, 
                     SFC=c(rep(sfc.levels, 2),NA, NA, NA),
                     FT=c(rep('Agg', 8), ft.levels),
                     num=1:11) %>%
  select(num, Model, SFC, FT, everything())

#####################################

#ex.sfc.tab table, formatted using gt
extended.sfc.final <-ex.sfc.tab %>% 
  mutate(Model=c(rep(c('7 (ISI, SFC)', '9 (ISI_sa, SFC)'), each=4), 
                 rep('15 (ISI, FT)', 3))) %>%
  select(-num) %>%
  rename('SFC \n (kg/m2)'=SFC, 'Model (predictors)'=Model) %>%
  gt() %>%
  tab_header(
    title = "Extended prediction table for multivariate models" #,
#    subtitle = "Your subtitle (if needed)"
  ) %>%
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  cols_width(
    'Model (predictors)' ~ px(100),
    everything() ~ px(60)
  ) %>%
  tab_spanner(
    label='Predicted ROS (m/min)',
    columns=4:6
  ) %>%
  tab_style(
    style = cell_borders(
      sides = 'bottom',
      color = "black",
      weight = px(1)
    ),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    table.width = pct(100),
    column_labels.border.top.width = 2,
    column_labels.border.top.color = "black",
    column_labels.border.bottom.width = 2,
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table.border.bottom.width = 2,
    data_row.padding = px(3),
    column_labels.border.bottom.style = 'none',
    table_body.hlines.color = 'white'
  ) %>%
  opt_horizontal_padding(scale = 0.5) %>%
  opt_vertical_padding(scale = 0.5) %>%
  #tab_source_note(
  #  source_note = "Your source note or additional information here"
  #) %>%
  opt_table_font(font = "Arial") #%>% gtsave("your_table.html")

#compare SFC to sqrt(SFC)
ef.sfc.mod1 <- ef.r.squared(actual=augment(m7.sros.ISI2SFC.mod) %>% 
                              pull(ROS), 
             pred=augment(m7.sros.ISI2SFC.mod) %>% pull(.fitted))

ef.sfc.mod2 <- ef.r.squared(actual=augment(m9.sros.isim2SFC.mod) %>% 
                              pull(ROS), 
             pred=augment(m9.sros.isim2SFC.mod) %>% pull(.fitted))

ef.sfc.mod10 <- ef.r.squared(
  actual=augment(update(m7.sros.ISI2SFC.mod, ~.-sqrt(SFC) + SFC)) %>% 
    pull(ROS),
  pred=augment(update(m7.sros.ISI2SFC.mod, ~.-sqrt(SFC) + SFC)) %>% 
    pull(.fitted))

ef.sfc.mod20 <- ef.r.squared(
  actual=augment(update(m9.sros.isim2SFC.mod, ~.-sqrt(SFC) + SFC)) %>% 
    pull(ROS), 
  pred=augment(update(m9.sros.isim2SFC.mod, ~.-sqrt(SFC) + SFC)) %>% 
    pull(.fitted))

```

### [Figure 4, high influence]

```{r label=Fig4, echo=FALSE}
#Do nlstools jackknife resampling to identify overly influential obs
#do this on crisiCon, crisimCon, 

#jack.crisiCon <- nlstools::nlsJack(sf.con.mod)  #old, fixed a
jack.crisiCon <- nlstools::nlsJack(m12.conISI)
#summary(jack.crisiCon)
#crisiCon: rows 10, 28, 49, 51 (s.con2)

jack.crisimCon <-nlstools::nlsJack(m13.conSa)
#jack.crisimCon <-nlstools::nlsJack(sf.crisimCon.mod)
#summary(jack.crisimCon)
#crisimCon: rows 10, 28, 51

jack.crisimAgg <-nlstools::nlsJack(m11.agSa) #s.fires.mod
#28, 52, 54, 60, 83, 88, 89, 91  #omit 83; no SFC

jack.crisiAgg <-nlstools::nlsJack(m10.agISI) 
#28, 58, 59, 60, 88, 91  #only points sig. to both b and c

#for lm models, use broom::augment to run Cook's D
#high influence: D >1, or 0.5, or 4/n
#n=84 #aggregate with SFC
#n=91 #aggregate full
#n=51 #con no torch
#4/n = 0.04 - 0.08

#Just pull high cook's D values
cook.isim2sfc <- broom::augment(m9.sros.isim2SFC.mod) %>%
  select(1:4, .cooksd) %>%
  filter(.cooksd > 0.07) %>% #good enough for 4/n for n=51
  mutate(isi.m=sqrt(`I(isi.m^2)`) %>% as.numeric(), 
         SFC=`sqrt(SFC)`^2)
#needs the 'as.numeric' to plot

cook.ISI2sfc <- broom::augment(m7.sros.ISI2SFC.mod) %>%
  select(1:4, .cooksd) %>%
  filter(.cooksd > 0.077) %>%
  mutate(ISI= sqrt(`I(ISI^2)`) %>% as.numeric(), 
         SFC=`sqrt(SFC)`^2)

#cook.isim2sfc %>% top_n(.cooksd, n=10) %>% arrange(desc(.cooksd)) %>% select(1:3, .cooksd)
#cook.ISI2sfc %>% top_n(.cooksd, n=10) %>% arrange(desc(.cooksd))
#isim2sfc: rows 52, 28, 88, 60
#num: 117, 68, 232, 204
#ISI2sfc: rows 58, 28, 88, 59, 60

#model labels
lab1 <- 'm9' #change to dynamic label 
lab2 <- 'M11'
lab3 <- 'm17'  #m17.power.sa

sf.m14 <-function(ws, mcf) {
  predict(m14.power, newdata=data.frame(ws=ws, MC.FFMC=mcf)
  )        
}

# sf.m17 <- function() {
#   predict(m17.power.sa, newdata=list(MC.SA=8, ws=ws))
# }

  
fig4 +
  # geom_point(data=cook.isim2sfc, shape=5, colour='black', 
  #            size=5) + #diamonds around high Cook's D vals
  geom_point(data=s.fires.mod %>% slice(c(28, 52, 54, 60, 88, 
                                          89, 91)) %>% 
              select(fire, ISI, isi.m, ROS, FT, SFC), shape=2,
             colour='black', size=5) + #triangles - influential to agg mods
  geom_point(data=s.con2 %>% slice(c(10, 28, 51)) %>% 
              select(fire, ISI, isi.m, ROS, FT), shape=5,
              colour='black', size=5) + #diamonds - influ to con mods
  stat_function(fun=sf.isim2sfc.fun, args=list(SFC=1), color='purple', #m9
                linetype='dashed') +
#  stat_function(fun=sf.isim2sfc3.fun, color='red') +
  stat_smooth(data=powerconsa.df, colour='red') + #m17
  #stat_function(fun=sf.crisim.fun, color='purple') +
  stat_function(fun=fun.m11, colour='pink') +

  geom_text(x=23, y=sf.isim2sfc.fun(isim=23, SFC=1)+1, 
            label=lab1, #m9 label
            colour='purple', size=4) +
  geom_text(x=24, y=fun.m11(24)-1, label=lab2, #to.here Dec31 2025
            colour='pink') + #m11
  geom_text(x=19, y=fun.powersa(ws=25, ffmc=92)+1, 
            label=lab3, #m17
            colour='red') +
  labs(x=expression(ISI[sa]), y='ROS (m/min)', size=expression(SFC~(kg/m^{2})), ## ~ is space; ^{2} is superscript 2 for squared term
       colour='Fuel type') +
  theme(legend.position='none') +
  coord_cartesian(xlim=c(0, 25), ylim=c(0, 14))
  
```

*Caption: Figure 4. Surface fire rate of spread (ROS) observations and selected fitted models, using the stand-adjusted initial spread index (ISI~sa~). Colours indicate fuel type as follows: red: boreal conifer; blue: ponderosa pine-Douglas-fir (PPDF) adjusted to 95 %-cured condition; green: deciduous; gray: original PPDF (not modelled). Size indicates surface fuel consumption. Observations with black centres are documented wildfires; the remainder are experimental fires. Observations with diamonds and triangles are high influence observations (both fitted parameters) associated with nonlinear conifer (M14) and aggregate (M11) models, respectively, based on jackknife resampling.*

Figure 4 shows the surface ROS observations plotted by overall fuel type (boreal conifer, deciduous, or PPDF) and SFC against *ISI~sa~*, along with three of the fitted models: M9 (calculated at SFC=1.5 kg m^-2^), M11, and M14 (boreal conifer only). PPDF fires adjusted to 95% curing conditions were used in model fitting, while the original observations (not included in models) are also shown.

Figure 5 shows the observations based on the ISI, along with selected fitted and benchmark models. Model 15 is shown separated by FT class – boreal conifer (Con), PPDF (95% cured), or deciduous (Decid). The interaction between FT and ISI is apparent, with different slopes for each fuel type function. This shows the limitations of this model, as the PPDF fuel type function is not credible for ISI > 15 or so. Figure 5 also shows are the noted overprediction tendencies of the C-6s and C-4s models.

As Table 1 indicates, 'aggregated' dataset models (e.g. M10, M15) performed generally worse (higher MAE, MAPE, lower Efron's R-squared) than the boreal conifer-based models (e.g. M13) when using ISI-based predictors, although M15 performed relatively well overall, with MAE \~ 1 and ER2 of 0.629.

#### Influential observations #not sure if this is needed

Individual observations were evaluated for leverage in the best models using Cook's Distance and jackknife resampling. For non-linear models 10, 11, 13 and 14#, observations were flagged when the difference between model parameters calculated with and without individual estimates, $\Delta$, was $\Delta>\frac {2 s} {\sqrt{n}}$, where *s* is the standard error of the parameter estimate and *n* is the sample size [@baty2015]. For linearized models (Models 7 and 9#), observations with Cook's D \> 0.78 were flagged as influential, based on the 'high influence' threshold of 4/n, using n=51 from the conifer dataset (not shown; see Appendix#). High influence observations are shown in Figures 4 and 5 and consist mainly of high *ISI*/*ISI~sa~* and high ROS observations, particularly wildfires.

### [Fig 5]

```{r label=Fig5, echo=FALSE}
lab4 <- 'M15'
lab5 <- 'M13'

fig5.draft <-
fig5 + 
  geom_point(data=s.con2 %>% slice(c(10, 28, 49, 51)) %>% #con mods jackknife
               select(ROS, ISI, SFC, FT), shape=5, size=5, colour='black') +
  # geom_point(data=s.fires.mod %>% slice(c(28, 58, 59, 60, 88, 91)) %>% #agg jk
  #              select(ROS, ISI, SFC, FT), shape=2, size=5, colour='black') +
  geom_point(data=cook.ISI2sfc, shape=2, size=5, 
             colour='black') + #triangles around high cooks D vals
  stat_function(fun=sf.m15b, args=list(
    ftd=0, ftp=0), color='red2', alpha=0.4) + #M15b con
  stat_function(fun=sf.m15b, args=list(
    ftd=0, ftp=1), color='darkblue', alpha=0.4) + #M15b ppdf
  stat_function(fun=sf.m15b, args=list(
    ftd=1, ftp=0), color='green3', alpha=0.4) + #M15b decid
  stat_function(fun=sf.asyCon.fun, color='darkred') +  
  geom_text(x=10, y=c4s(10)+3, label='C-4s', colour='darkgrey') +
  geom_text(x=25, y=sf.m15b(isi=26), label=lab4) +
  geom_text(x=23, y=c3s(24)-1, label='C-3s', colour='darkgrey') +
  geom_text(x=26, y=sf.asyCon.fun(26)+1.2, label=lab5, colour='darkred')+
  geom_text(x=19, y=c6s(19)+1.5, label='C-6s', colour='darkgrey') +
  # stat_function(fun=c3, colour='gray') +
  # geom_text(x=20, y=c3(20)-1.5, label='C-3', colour='gray') +
  coord_cartesian(x=c(1, 30), y=c(0, 25)) +
  labs(x='ISI', y='ROS (m/min)') +
  theme(legend.position='none')
#  geom_point(data=d1.missing, inherit.aes=TRUE)

#Simpler, better Fig5 with con data, ISI
#Points with ISI/mc
ROS.power.points <- fun.power(
  ws=wind.range, ffmc=ffmc.power) #ROS using power mod; ffmc91.7
ROS.power.points2 <- fun.power( #for low range
  ws=wind.range2, ffmc=ffmc.power2) #ROS with ffmc88
ROS.power.points3 <- fun.power(
  ws=wind.range3, ffmc=ffmc.power3) #ROS w/ ffmc84.4
isi.power.points <- ISI(ws=wind.range, ffmc=ffmc.power)
isi.power.points2 <- ISI(ws=wind.range2, ffmc=ffmc.power2)
isi.power.points3 <- ISI(ws=wind.range3, ffmc=ffmc.power3)

power.df <-data.frame(ROS=ROS.power.points,
                      ISI=isi.power.points)
power2.df <-data.frame(ROS=ROS.power.points2,
                       ISI=isi.power.points2)
power3.df <-data.frame(ROS=ROS.power.points3,
                       ISI=isi.power.points3)
powercon.df <-bind_rows(power.df, power2.df, power3.df)

#Figure 5 maybe

#labels
#
fig5.ag5 <- ggplot(s.con, aes(x=ISI, y=ROS)) + 
  geom_point() + 
#  geom_point(data=power.df, colour='red') + 
  stat_smooth(data=powercon.df, colour='red',
              method='gam', linewidth=0.5)+  #new m16 model work
  stat_function(fun=fun.m12, xlim=c(0, 50), colour='gray5') + #sl.asy
  stat_function(fun=fun.m3, xlim=c(0, 50), colour='blue') + #fixed
  #stat_function(fun=sf.powersa, xlim=c(0, 70), colour='red')+ #power func
  stat_function(fun=asym4, xlim=c(0, 50), 
                colour='gray', linetype='dashed') + #asymptote
  coord_cartesian(ylim=c(0, 30), xlim=c(0, 45)) +
  geom_text(label='m12', x=30, y=fun.m12(30)-2) +
  geom_text(label='m3', x=28, y=fun.m3(28)+4) +
  geom_text(label='m17', x=35, 
            y=fun.power(ws=38, ffmc=ffmc.power)+2) +
  theme_classic()

fig5.ag5



```

*Caption: Figure 5. Surface fire observations by ISI, ROS, and fuel type (FT): green (deciduous; Decid), blue (Ponderosa pine-Douglas-fir; PPDF), or red (boreal conifer; Con), along with sigmoidal model M13 (Con only), fuel type (FT) category model M15 (Con, Decid and PPDF), and FBP-era models (C-3s, C-4s, C-6s, C-3). PPDF fires are shown both with their original observed ROS (gray, not modelled), and normalized to 95% cured condition (blue, modelled). Model labels are colour-coded to line colour except for M15. Observations with diamonds represent high influence observations (for both fitted parameters) associated with M13, based on jackknife resampling.*

## 5. Discussion

### Operational surface ROS models

Since wildfires in conifer stands spreading under higher danger conditions tend to be crown fires [@vanwagner1977a; @beverly2020; @cruz2022], it is unsurprising that the majority of surface fires in our database occurred during moderate-level fire danger indices and wind speeds. Crown fire occurrence in conifer forests has long been modeled using canopy base height and surface fire intensity [@vanwagner1977], or more recently, surface fuel consumption as a surrogate [@cruz2004; @perrakis2023]. This explains the existence of a few surface fires (in high-CBH pine stands) in our database under high danger conditions (i.e., dry and-or windy: *ISI* \> 10). Because of the lack of experimental data from fires ignited under high danger conditions, a small number of wildfires exhibiting surface fire behaviour were also included to populate this range of *ISI*/*ISI~sa~* values. Being few in number, individual high danger observations tended to be highly influential in regression models. Despite this warning, there is no way of removing these observations without significantly affecting the models and their range of inference. Primary source descriptions that exist for these wildfires [e.g. @vanwagner1965b] reflect their age and simple estimation methods; we would  expect high error with such a dataset [@filkov2018], and some of the highest ROS observations are likely overestimates of actual spread. Overall, our surface fire database represent a range of ROS values (0.3–12.0 m min^-1^) previously described as 'slow' to 'fast', but primarily in the 'moderately slow' (1–3 m min^-1^) to 'moderately fast' (3–10 m min^-1^) category [@alexander1989].

As wildfire hazard reduction treatments become more widespread, where stands with high CBH and low surface fuel loading are engineered to resist crown fire [e.g., @agee2005; @beverly2020], there is a need to estimate sROS under higher danger conditions. The lack of data under more extreme conditions creates uncertainty that cannot be solved by these models alone but will require additional observations for validation, from experimental burns or high resolution wildfire observations where surface fire behaviour can be identified. These might come from fires in tall pine or Douglas-fir stands with CBH \> 10 m, for instance [@perrakis2025]. As the M25 model assessment suggests that conifer crown fires are ~ 6 times faster than surface fires under the same weather conditions, the corollary is that fuel treatments (such as pruning or removal of ladder fuels) can ideally reduce ROS by 5/6, or 83%. This is a highly preliminary finding achieved by comparing some very simple empirical models, but may prove to be a useful heuristic. Notably, this simple assessment does not discriminate between passive and active crown fire spread [@vanwagner1977], with the latter much faster-spreading, depending on ws and canopy fuel characteristics [@cruz2005; @perrakis2020].  

### Predictors of surface ROS

While the *ISI* is old and familiar, it was one of the strongest ROS predictor variables, in its original or stand-adjusted form. The *ISI* was recently found to be the variable most closely correlated to area burned during the record-breaking 2023 Canadian wildfire season [@jain2024], and was previously significantly correlated with probability of containment in Alberta black spruce stands [@beverly2017]. Database values used in the analysis represent indices that best represent burning conditions according to primary sources; for forecasting purposes, we expect hourly *ISI* values to perform better than daily values [@beck2002]. The *ISI~sa~* quantifies additional influences based on stand properties and longer-term moisture effects (i.e., the DMC and 'season' variables) [@wotton2007], and it is encouraging that *ISI~sa~* was the single best predictor of the overall forest dataset, with the best performance being with sigmoidal modified Chapman-Richards equation, with or without SFC as an added input (Table 1: Models ). For the pine and spruce data alone, *ISI* alone was slightly superior, possibly because the other stand condition variables associated with *ISI~sa~* were not helpful in further discriminating among these similar experimental stands. As discussed in previous studies, wind speed influences on ROS have often been fitted to power functions as *WS^b*, where *b*>1 in some studies but *b*=1 or *b*<1 more often under high wind speeds [fernandes2009]. For the range of fires and *ISI* conditions described here (e.g., *ISI* < 30 or so, including some extrapolation), these model forms seem adequate.  

The present surface fire models involve mainly weather and moisture-related inputs, with some influence from fuel type and SFC in some model forms. In-stand ground-level wind speed ('mid-flame') is used in several empirical models due to its apparent direct influence on flame propagation [@rothermel1972; @anderson2015]. We might therefore expect overstory vegetation density or structure to influence ROS considerably in our models, due to the vegetation influence on ground-level wind speed, turbulence, and other aspects of micrometeorology [@amiro1990; @dupont2008; @moon2019]. However, the variability in our data did not lend itself to strong fuel type differences, and fuel type was mainly a useful covariate for reflecting the difference between PPDF fires and other fuel types. As for density class, it was only significant in *ISI~sa~*-based models where density class already influences fuel moisture through the @wotton2007 model; as such, it was considered confounded and likely overfitted. SFC was a useful second ROS predictor (Models 7, 9), though it itself must be modelled from fuel loading or fuel type and indices of moisture deficit. Practical methods for estimating SFC include the FBP fuel type-based models based primarily on the buildup index (BUI) [@forestrycanadafiredangergroup1992] or other similar empirical consumption models [@degroot2009]. Importantly, the influence of SFC in Models 7 and 9 was highest at low *ISI* (or *ISI~sa~*) values, and became negligible under higher *ISI* conditions (Appendix C).

### Using final surface rate of spread models

The primary value of such surface ROS models may be to inform varying fuel structure scenarios in dynamic modelling systems [e.g., @perrakis2020; @perrakis2024b; @cfsfiredangergroup2021], where tools such as calculators and lookup tables enable users to test various fuel structure and weather scenarios. As noted, conifer species was generally not a significant ROS predictor; however, differences in experimental design (e.g. plot size, fuelbreak width, frequency of wind monitoring) may mask small but significant differences. Laboratory experiments have suggested that a range of conifer litterbed characteristics, including species and bulk density, can affect heat fluxes and overall flammability [@cornwell2015; @wilson1990; @campbell-lochrie2021]; however, laboratory results can be challenging to apply to complex natural forest fuelbeds, requiring a high number of replicates as heterogeneity increases [@mulvaney2016]. In our models, deciduous observations helped increase the scope of models and to evaluate ROS differences between the major fuel types (conifer vs deciduous forests). However, no new data was provided beyond the range of the original D-1 spread model, which matches the noisy deciduous fire experiment dataset adequately.

A small number of models stand out as superior than the others in terms of practical applicability, particularly for the operational context (Table 1). These are the models more likely to predict new observations within a reasonable accuracy range, e.g. +/- ~30% [@cruz2013]. These include Models 13 and 14, nonlinear curves fitted to boreal and sub-boreal conifer stands with the highest ER2 and lowest MAE values, for use with *ISI* (M13) and *ISI~sa~* (M14) inputs; Model 9, a good 'aggregated data' model suitable for a range of forest types, featuring several user input options thanks to its *ISI~sa~* and *SFC* predictors; and perhaps the '25 % model', the simplest model for rapid or emergency use. Model 15 reflected the influence of fuel type (Conifer, Deciduous, or PPDF); while this is a useful contrast, due to the dearth of PPDF data and assumptions involved, it is not very credible without further testing or refitting with additional observations.  

Although stand density class variables were not significant on their own, the models using *ISI~sa~* incorporate fuel moisture differences via the *mc~sa~*. This allows for some ability to represent, for instance, forest thinning treatments, where physical modelling studies have suggested that reducing stand density can increase surface ROS [e.g., @parsons2018; @marshall2020]. However, the effects of such differences are relatively small in the present sROS models as the only relationship being simulated is the effect of categorical density differences on fuel moisture in the *mc~sa~* model; expected changes to in-stand winds are not represented. In addition, more significant density changes (e.g. clearcutting or severe density reductions) are unlikely to be adequately represented by the *mc~sa~* categories. For instance, in a pine stand under FFMC 92, DMC 100, WS~10~=15 km h^-1^ conditions in summer, decreasing density from 'high' (H) to 'moderate' (M) or 'low' (L) conditions would result in an increase from 3.5 to 3.7 to 4.6 m min^-1^, respectively, using Model 9 (assuming SFC of 1.5 kg m^-2^): a maximum density-dependent difference ($\Delta$) of 1.1 m min^-1^. Varying SFC between 0.5 and 3.5 kg m-2 could further stretch $\Delta$ to 1.8 m min^-1^, holding weather indices constant. This is a small difference for capturing the full range of silvicultural management options or stand conditions; for instance, tree density reductions of 70-80% are common in hazard reduction treatments [@prichard2010; @hirsch1999]. The present models are likely most appropriate for moderately open to closed conifer stands; a lower limit for crown closure would likely to be near 20 % (the level of opening of the more open PPDF and jack pine experiments). Below this limit, very open forests and parkland or savannah-type stand structure would be expected to have much greater wind penetration [@albini1979; @moon2019] and might support significantly faster surface fire spread than appears in our data.

As noted, the major limitation of these ROS models and underlying data dataset are the paucity of observations at higher danger conditions (*WS~10~* or *ISI*). For improving empirical models, there is no substitute for additional high quality observations. Surface fire observations spreading under high indices would necessarily have high LCBH and-or low SFC; else they would be expected to exhibit crown fire behaviour. Additional surface fire observations under such conditions (high wind, low moisture) are unlikely to come from experimental burning, but could be detected from opportunistic imaging of spreading wildfires [e.g., @hart2021; @valero2018]. Until such data are acquired , predictions beyond the range of data (i.e., *ISI* \> 19.2 or *ISI~sa~* \> 24.5 in conifer stands) constitute extrapolation. While never recommended, extrapolation is often necessary in operational settings [e.g., @forestrycanadafiredangergroup1992]. For such purposes (e.g., *ISI* > 15 or *ISI~sa~* > 20), we suggest the modified Chapman-Richards models (10, 11, 13 or 14) to avoid the more extreme results generated by exponential models (with *ISI^2^* or *ISI~sa~^2^*) under high wind - dry fuel conditions. For example, the conditions in the previous paragraph example (pine stand in summer) but with WS~10~=40 km h^-1^ (producing ISI of `r ISI(92, 40) %>% round(1)` ) would predict ROS of `r predict(m3.con.ISI.mod, newdata=list(ISI=ISI(92, 40))) %>% round(1)` m min^-1^ using Model 3, with its *ISI^2^* term. Model 13, a semi-sigmoidal model, predicts much lower ROS (`r sf.asyCon.fun(ISI(92, 40)) %>% round(1)` m min^-1^) under such conditions. While the actual sROS of this hypothetical example is unknown (ROS could be +/- 50 % or more of the predicted value; see below), a surface fire with ROS \> 50 m min^-1^ in conifer forest is highly unlikely [Figure 2; see also @cruz2005; @cruz2019].

Finally, the 25% model is presented in the same vein as the Cruz and Alexander '10% rule' [@cruz2019] and '20% rule' [@cruz2022a] models - as an approximate value suitable for mental arithmetic and rapid field use. The model with slope of $\beta_1 =0.25$ is preferred over a slope of 0.2 due to its better fit under higher wind speeds, oferring a modest safety margin in the face of uncertainty. Importantly, the unit difference (km h^-1^ vs m min^-1^) is critical in understanding this model for proper usage. An exact analogy with, for instance, the 10% rule equates the present 25% model to 1.5 % of the *WS~10~* after unit conversion. This also presents an additional finding of interest: on average, experimental conifer crown fires in Canada are about 6 times faster than experimental surface fires under similar wind speeds. This is calculated based on the approximation for crown fires as 8.4 % of the *WS~10~* [@cruz2019] and the mean of the 20% and 25% ws sROS models (8.4/1.5=5.6 and 8.4/1.2=7; the mean value is 6.3).

### [Table 2: Expected accuracy]

```{r label=expectAcc, echo=FALSE, warnings=FALSE}

#MAPE
#sros.isim2SFC.mod
pred1 <- broom::augment(m9.sros.isim2SFC.mod) %>% 
  select(ROS, `I(isi.m^2)`, .fitted) %>%
  rename(pred9=.fitted) %>%
  mutate(isi.m=sqrt(`I(isi.m^2)`),
         ape=abs((ROS-pred9)/ROS),
         diff=abs(pred9-ROS))

#MAPE table, M9
#sros.isim2SFC.mod
mape.m9 <- pred1 %>% #isi.m 12 appears to be a threshold
  group_by(ISI_sa=if_else(isi.m < 12, 'ISI<12', 'ISI>12'), #group by hi/lo 
           Prediction=if_else(ROS < pred9, 'Over', 'Under')) %>% #over/under pred 
  summarize(MAPE=mean(ape) %>% round(2), 
            Q90APE=quantile(ape, 0.9) %>% round(2)) %>% #MAPE and 90th of APE
  ungroup() 

# mape.m9 %>% 
#  gt()

#MAE table, M9
mae.m9 <- pred1 %>% #isi.m 12 appears to be a threshold
  group_by(ISI_sa=if_else(isi.m < 12, 'ISI<12', 'ISI>12'), #group by hi/lo 
           Prediction=if_else(ROS < pred9, 'Over', 'Under')) %>% #over/under pred 
  summarize(MAE=mean(diff) %>% round(2), 
            Q90AE=quantile(diff, 0.9) %>% round(2)) %>% #MAE and 90th of AE
  ungroup() 

pred.m9 <- full_join(mae.m9, mape.m9) 

pred.m9 %>%
  gt() %>%
  tab_style(
    style = cell_borders(
      sides = 'bottom',
      color = "black",
      weight = px(1)
    ), 
  locations=cells_column_labels() ) %>%
  tab_options(table_body.hlines.color = 'white') %>%
  tab_source_note(
    source_note = "Note: The threshold between 'High' and 'Low' ISI_sa values is 12"
  )

```

*Caption: Table 2. Expected model accuracy, Model 9.*

### Expected accuracy {#expected-accuracy-1}

The MAE and MAPE values (Table 1) can be used to calculate the mean and expected (e.g. 90th percentile or quantile) error associated with each model. Table 3 shows the mean and 90th quantile absolute error (MAE, Q90AE, respectively) and absolute percentage error (MAPE, Q90APE, respectively) using the example of Model 9, with $sROS=f(ISI_{sa}, SFC)$. Since there appeared to be a difference between the over- and under-prediction error potential at lower versus higher fire danger levels (e.g., Fig. 4), these categories are shown separately. Thus, Surface ROS errors of 1-2 m min^-1^ (approximate rounding of mean and Q90 absolute error of 0.6 – 1.7; Table 3) should be expected at *ISI~sa~* \< 12; and larger errors of perhaps 2-4 m min^-1^ (MAE and Q90AE of 1.7 – 3.5) may be expected in real world use at *ISI~sa~* of 12 – 25. In approximate percentage terms, underprediction by 30-60 %, and overprediction by 70-170 % is to be expected with these models.

While it may be inappropriate to compare the performance of fitted models in their native dataset with that of supposedly independently-derived models, it is apparent that some of the FBP-era models performed very poorly in predicting surface ROS. Negative ER2 values and MAPE of 150 – 380 % suggest that the C-4s and C-6s models perform worse than a null model using only the mean of all observations. These models are therefore not recommended for predicting surface fire behaviour.

Under very low danger conditions (e.g., FFMC \< 75 or ISI \< 1), ignition in needle fuel substrates becomes highly unlikely [@beverly2007; @nadeem2020], so ROS is a minimal concern. It is expected that the quality and quantity of source data will improve over time, allowing for periodic reanalysis and improvement of these models.

### Final verdict
As for fuel type-specific models, users may continue to use the D-1 and C-3s models, which hold up well compared to their respective datasets. Under high danger conditions, the limitations of the Chapman-Richards function may prove limiting, however, favoring one of the newer models presented here. Ultimately, all of these models would benefit from additional data and validation, and should be understood to be valid within the assumptions and constraints of their background datasets. 


## 6. References

::: {#refs}
:::

## 7. Appendices

### Appendix A: Fires in Ponderosa Pine-Douglas-fir stands in BC
#### Surface fuel consumption

Seven\* experimental fires were conducted in open Ponderosa pine-Douglas-fir forest stands in the Lower Dewdrop Range near Kamloops, British Columbia, in 1978-79. These fires were well documented in theses by Nyberg (plots 1-6) [@nyberg1979] and Smaill (plot 9) [@smaill1980]. Summary information and photographs were incorporated into the FBP System C-7 fuel type, where these data were combined with several wildfire observations to fit and estimate the various fuel type functions and parameters [@forestrycanadafiredangergroup1992; @degroot1993].  

The Dewdrop PPDF observations were reanalyzed from the original document records in order to merge these fires into the modelling database with common units and analysis methods. Stand structure at the Lower Dewdrop consisted of a low density Ponderosa pine-dominated overstory and mostly herbaceous understory, with mean canopy closure of approximately 32 % [@nyberg1979]. Litter and duff cover were described as light and patchy [@nyberg1979]. In the FBP System database, surface fuel consumption (SFC) was reported for only one observation (Plot 9), with a very high total SFC value of 5.3 kg m^-2^, dominated by \> 5 kg m^-2^ of woody fuel consumption.

The original SFC estimate for Plot 9 included consumption of all downed woody fuels, including from large diameter coarse woody debris (CWD; \> 7.6 cm). While methodologically consistent with other FBP experimental burns [@stocks1987b; @stocks1989], the Plot 9 CWD consumption represents the great majority of the total SFC and represents an outlier compared to other FBP System experiments. For instance, the mean CWD proportion of SFC at the Ontario Kenshoe Lake and Sharpsand Creek sites was 9.2 % [c.f. @stocks1987b; @stocks1989], significantly different from the 50.2 % proportion of consumption at Dewdrop (Mann-Whitney U-test: p \< 0.001). The difference is explained by both higher seasonal drought conditions during the Dewdrop burns (mean Drought Code (DC): 394 at Dewdrop vs 111 at Kenshoe Lake and 161 at Sharpsand; see @vanwagner1987 for DC description), and probably the overall frequency of larger diameter standing trees at Dewdrop, the source of the CWD (\> 17 % of trees in the '\>25 cm' DBH class; cf. [@nyberg1979]); compared with, e.g. \~ 1 % of trees in the '\> 23 cm' DBH class at Kenshoe Lake ('White River'); [@walker1975]).

Including contributions from CWD in surface fires is somewhat at odds with current understanding of flame front dynamics. Consumption studies suggest that most CWD consumption in PPDF stands occurs during post-frontal smoldering rather than during flaming combustion [@monsanto2008; @brown2003; @ottmar2014]. The high SFC at Dewdrop from smoldering CWD could therefore overpredict fire intensity as well as crown fire tendency [@vanwagner1977; @perrakis2023]. To compensate, new SFC values at Dewdrop were calculated excluding the CWD contribution. The updated SFC included only consumption from finer fuels (grass and herbs, litter, duff, and woody debris \< 7.6 cm) and resulted in a new (notably lower: 1.95 kg m^-2^) value for Plot 9.\*\* SFC values calculated using the same methods for Plots 1-6 yielded 0.50 – 1.42 kg m^-2^.

#### Herbaceous curing
The climate during the 1978 fire season may have also been somewhat anomalous, influencing moisture and fire behaviour during the Dewdrop experiments. Measurable rainfall was received at the Dewdrop weather station nearly weekly from April-August [@nyberg1979], an unusual occurrence in this summer-dry climate. Consequently, understory vegetation remained relatively green during the experimental fires. Relative proportions of live and dead grass and forb biomass were used to calculate percent curing values (*C*) for these observations, in the same manner as used in Australian and Canadian grass fire models [@cheney1998; @wotton2009]: $$C = \frac {GB_D} {(GB_D + GB_L)} \cdot 100 $$ [Eq.A1], where % *C* is the curing (%), and *GB~D~* and *GB~L~* represent dead and live grass and forb biomass (kg m^-2^), respectively. Using mean values from experimental and control plot sampling on each given date [@nyberg1979] gave % *C* values of 56-66 for Plots 1-6. The curing factor, *CF* was then calculated using the simple FBP System grass curing function that combines a gradual exponential rise at low *C* levels with a linear function at higher curing [@wotton2009]:
$$
CF=0.005 \cdot (exp(0.061C)-1)  \ \ \ \ \    ,\  C<58.8
$$
$$
CF=0.176 +0.02 \cdot (C-58.8) \ \ \ \ \ , \ C \ge 58.8
$$
[eq. A2]
For Plot 9, reported values are unfortunately less explicit between live and dead biomass [@smaill1980] and equation [A1] could not be used. Based on the slightly lower overall grass moisture value (22.7 %) and late season date, % C for that plot was estimated at 80%.

These analyses allowed us to incorporate the dry cordilleran Dewdrop experimental fires in our surface fire models (aggregated fuel type), despite being somewhat distinct from the primarily boreal conifer and deciduous experiments.

\*Plot numbers 1–6, burned in 1978, are described by [@nyberg1979]. Plot 9, burned in 1979, is described by [@smaill1980]. Plot 8 from the same site was apparently burned in 1980, but no further description or details have been located.

\*\*SFC estimates represent the differences between pre-burn and post-burn fuel loading, including contributions from woody fuels, grasses and forbs, and litter (the site featured negligible duff quantities). Estimating litter consumption values required an estimate of pre-burn litter depth, which was not reported but was instead taken from Ducherer et al. [@ducherer2009], a later series of experiments at a nearby site, \< 5 km away. The mean litter depth from control sites across all years and canopy positions: 3.3 cm).

### Appendix B: Matrix of predictors for model building

In comparing ISI-type models with FFMC- (or mcSA-) and wind speed-based models, the single predictor models using *ISI~sa~* (*ISI~sa~*/*ISI~sa~^2^*) were superior based on RMSE, ER2, MAE and MAPE; however, using ISI (ISI/ISI^2^), results were equivocal, with better (higher) ER2 for the ISI/ISI^2^ models, but also higher (worse) RMSE and MAE for single predictor models. For MAPE, the ISI model was superior to the ws + mc~FFMC~ combination.

###[Table A1: Variable matrix]

```{r label=VarMatrix, echo=FALSE, warnings=FALSE}
lp.mods.lst2 <- summary(lp.mods2)[[7]] 
lp.mods.lst3 <- summary(lp.mods3)[[7]] 
#uses lp.mods2 from the 'Complex modelling attempts' section

#following Perplexity code
wh <- summary(lp.mods3)$which  #generates rows=models, cols=(intercept, preds)

wh.df0 <- as.data.frame(wh) %>% select(-1) %>%  #get rid of intercept
  rownames_to_column('model_label') %>%
  mutate(model_id=row_number())

#identify which columns are predictors (all except model_id)
pred_cols <- setdiff(names(wh.df0), c('model_label', 'model_id'))

#model size per model
wh.df <- wh.df0 %>%
  mutate(
    mod_size = rowSums(across(all_of(pred_cols))))

#rank models within each size by current order
wh.models <- wh.df %>%
  distinct(model_id, mod_size) %>%
  group_by(mod_size) %>%
  arrange(model_id, .by_group=TRUE) %>%
  mutate(model_rank=row_number()) %>%
  ungroup() %>%
  filter(mod_size <= 5, model_rank <=4) # keep only sizes up to 4, best 3 #chg

#expand to predictor level
wh.long <- wh.df %>%
  inner_join(wh.models, by=c('model_id', 'mod_size')) %>%
  pivot_longer(
    cols=all_of(pred_cols),
    names_to = 'predictor',
    values_to = 'included') %>%
  filter(included)
  
#for each (mod_size, predictor), keep the *best* model
#based on frequency and best rank among those
by.size.pred <- wh.long %>%
  group_by(mod_size, predictor) %>%
  summarize(
    freq = n_distinct(model_rank),
    best_model_rank = min(model_rank),
    .groups = 'drop'
  )

#Build a score - higher freq is better, lower best_model_rank is better
#use min_rank on that score to deal with ties, and make gaps after ties
ranked <- by.size.pred %>%
  group_by(mod_size) %>%
  mutate(
    score = (-freq) * 10 + best_model_rank,  #any monotone transform is ok
    pred_rank = min_rank(score)  #for ties: 1, 1, 3 pattern
  ) %>%
  ungroup()

#keep only top 3 preds per size
# rank.top3 <- ranked %>%
#   group_by(mod_size) %>%
#  # filter(pred_rank <=3) %>%
#   ungroup()

#label columns by size only: best1, etc.
rank.top3b <- ranked %>%
  mutate(
    col_name=case_when(
    mod_size==1 ~ 'Best1v',
    mod_size==2 ~ 'Best2v',
    mod_size==3 ~ 'Best3v',
    mod_size==4 ~ 'Best4v',
    mod_size==5 ~ 'Best5v',
    TRUE ~ NA_character_)
  ) %>%
  filter(!is.na(col_name))

nice_table <- rank.top3b %>%
  select(predictor, col_name, pred_rank) %>%
  distinct() %>%
  pivot_wider(
    names_from = col_name,
    values_from = pred_rank)

# new.preds <- c(expression(ISI[sa]^{2}),
#                expression(ISI^{2}), expression(ISI[sa]),
#                'ISI', 'FTPPDF', 'FFMC', paste0(expression(mc[sa]),'_D3'),
#                'FFMC')

nice_table2 <- nice_table %>% arrange(Best1v, Best2v) #%>%
#  mutate(predictor=new.preds)  #doesn't work

```

```{r label=T.A1, echo=FALSE, warnings=FALSE}
#make pretty with gt()  Table A1
t.a1 <- nice_table2 %>%
  gt(rowname_col='predictor') %>%
  tab_header(
    title='Matrix of predictors using best ROS models',
#    subtitle='Values indicate predictor frequency scores'
  ) %>%
  tab_spanner(
    label='Values indicate ranking of best 1-5 variable (Best1v, Best2v, etc.) models, excluding intercept',
    columns=c(Best1v, Best2v, Best3v, Best4v, Best5v)
  ) %>%
  #NA values
  fmt_missing(
    columns=everything(),
    missing_text = '-'
  ) %>%
  tab_options(
    table_body.hlines.width =px(0),
    table_body.vlines.width=px(0),
    column_labels.border.bottom.width =px(0),
    table.font.size = px(11),
    heading.align ='left',
    table.border.top.width =px(1),
    table.border.top.style ='solid', 
    table.border.bottom.width = px(1),
    table.border.bottom.style ='solid' 
  )
  
t.a1

```

### Appendix C: Final model coefficients
Table A2 shows the full table of coefficients and statistics for the models presented in the main text. 

###[Table A2]

```{r label=FinalMods, echo=FALSE, warnings=FALSE}
#Table A2 - final mod coefficients
#build table of coefficients for all final models in 
#acc.tab4 (including c6s, c4s, etc.)

#process model coefs from mod.list.long

#extract fitted models (not preexisting functions)
mod.list.models <- mod.list.long[1:15]

#assign model names with numbers
final.names <- as.data.frame(modnames) %>% 
  mutate(num=row_number(), 
         Model=str_c(num, '. ', modnames))

#produce tidy tables of model parameters

#tidy mod.list to create simple list object
param.list <- purrr::map(
  mod.list.models, tidy) #present clean table of model params and stats

names(param.list) <- slice(final.names, 1:15) %>% 
  pull(Model)

#change list to data frame
mod.params.df <- bind_rows(param.list, .id='Model') %>%
  rename(Term=term, Estimate=estimate) %>%
  mutate(Model=if_else(Model==lag(Model), '.', Model)) 
  #if name is same as previous, just write a dot .

mod.params.df$Model[1] <- names(param.list)[[1]] #fix first name

#add 25%ws model
ws.mod <- 

print(mod.params.df, n=nrow(mod.params.df))
         
  

```
*Caption: Table A2. Estimates and statistics for the fitted models presented in the main text. See Table 1 for model comparisons and evaluation metrics). *

### Appendix D: Extended SFC and fuel type model estimates

Extended ROS predictions were compared for the three aggregated data models with two predictors, Models 7, 9 and 15: *ISI* (or *ISI~sa~*) and *SFC,* and *ISI* and fuel type (Table A3). SFC-based models used a *sqrt(SFC)* term, which performed slightly better (*ISI*: Efron's R^2^=`r ef.sfc.mod1 %>% round(4)`); *ISI~sa~*: Efron's R^2^=`r ef.sfc.mod2 %>% round(4)`) than an untransformed *SFC* term (*ISI*: `r ef.sfc.mod10 %>% round(4)` ; *ISI~sa~*: `r ef.sfc.mod20 %>% round(4)` , respectively).

The fuel type comparisons are from Model 15, a model based on linear a *ISI* term with an interaction factor with FT (fuel type). This makes for higher ROS estimates with the PPDF fuel type at lower ISI values (ISI < ~13), but higher ROS with the boreal conifer fuel type at higher ISI values. This model is not recommended for PPDF fuels for ISI > 13 for this reason; one of the non-fuel type specific models would be preferable (e.g. Model 13) for those conditions.  

###[Table A3 - extended SFC; M7, M9, M15]

```{r label=ExtSFC, echo=FALSE}

extended.sfc.final
```

*Caption: Table A3. Extended predictions for models 7 and 9, using varying values of predicted Surface Fuel Consumption (SFC; Models 7 and 9) from 0.7 kg m^-2^ to 5.0 kg m^-2^, fuel types (FT; Model 15) Deciduous (Decid), Conifer (Con) or Ponderosa pine-Douglas-fir (PPDF, adjusted to 95% cured), and ISI or ISI~sa~ values from 5 to 15. See Table 1 for model predictor forms.*
